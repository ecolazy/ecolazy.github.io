"use strict";(self.webpackChunkmy_website_2=self.webpackChunkmy_website_2||[]).push([[9209],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>g});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function r(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),d=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},c=function(e){var t=d(e.components);return n.createElement(l.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,c=r(e,["components","mdxType","originalType","parentName"]),p=d(a),h=i,g=p["".concat(l,".").concat(h)]||p[h]||u[h]||o;return a?n.createElement(g,s(s({ref:t},c),{},{components:a})):n.createElement(g,s({ref:t},c))}));function g(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=a.length,s=new Array(o);s[0]=h;var r={};for(var l in t)hasOwnProperty.call(t,l)&&(r[l]=t[l]);r.originalType=e,r[p]="string"==typeof e?e:i,s[1]=r;for(var d=2;d<o;d++)s[d]=a[d];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}h.displayName="MDXCreateElement"},9394:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>o,metadata:()=>r,toc:()=>d});var n=a(7462),i=(a(7294),a(3905));const o={slug:"constructing-a-3d-egg-shape-from-regular-polygons",title:"Constructing a 3D Egg Shape from Regular Polygons",authors:"ecolazy",tags:["hello","docusaurus"]},s="Constructing a 3D Egg Shape from Regular Polygons",r={unversionedId:"combined",id:"combined",title:"Constructing a 3D Egg Shape from Regular Polygons",description:"As engineers and designers, we are often approached with unusual and challenging requests. One such request came from an artist who asked us to help find a suitable geometry for a large egg sculpture. Intrigued by the opportunity to collaborate with an artist and apply our skills in a creative context, we set out to identify possible geometries using generative algorithms in Grasshopper 3D.",source:"@site/docs/combined.md",sourceDirName:".",slug:"/constructing-a-3d-egg-shape-from-regular-polygons",permalink:"/docs/constructing-a-3d-egg-shape-from-regular-polygons",draft:!1,tags:[{label:"hello",permalink:"/docs/tags/hello"},{label:"docusaurus",permalink:"/docs/tags/docusaurus"}],version:"current",frontMatter:{slug:"constructing-a-3d-egg-shape-from-regular-polygons",title:"Constructing a 3D Egg Shape from Regular Polygons",authors:"ecolazy",tags:["hello","docusaurus"]},sidebar:"tutorialSidebar",previous:{title:"Sun Shading Model With Radiance",permalink:"/docs/parametric-modeling/sun-shading-model-with-radiance"}},l={},d=[{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus",level:2},{value:"Docusaurus Plushie",id:"docusaurus-plushie",level:2},{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus-1",level:2},{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus-2",level:2},{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus-3",level:2},{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus-4",level:2},{value:"tags: hello, docusaurus",id:"tags-hello-docusaurus",level:2},{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus-5",level:2},{value:"tags: hello, docusaurus",id:"tags-hello-docusaurus-1",level:2},{value:"Docusaurus Plushie",id:"docusaurus-plushie-1",level:2},{value:"tags: hello, docusaurus",id:"tags-hello-docusaurus-2",level:2},{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus-6",level:2},{value:"tags: hello, docusaurus",id:"tags-hello-docusaurus-3",level:2},{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus-7",level:2},{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus-8",level:2},{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus-9",level:2},{value:"Docusaurus Plushie",id:"docusaurus-plushie-2",level:2},{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus-10",level:2},{value:"Docusaurus Plushie",id:"docusaurus-plushie-3",level:2},{value:"tags: hello, docusaurus",id:"tags-hello-docusaurus-4",level:2},{value:"Background",id:"background",level:2},{value:"Abstract",id:"abstract",level:2},{value:"Description",id:"description",level:2},{value:"Advantages",id:"advantages",level:2},{value:"Claims",id:"claims",level:2},{value:"Conclusion",id:"conclusion",level:2},{value:"The solar concentrator using a sphere with rotating mirrors is a novel and efficient way to capture and concentrate solar energy. The concentrator has several advantages over other solar concentrators, including its ability to reflect sunlight from a wide range of angles, its ability to concentrate solar energy into a small area, and its relatively easy manufacture and installation. The concentrator has the potential to be a cost-effective option for solar energy applications.",id:"the-solar-concentrator-using-a-sphere-with-rotating-mirrors-is-a-novel-and-efficient-way-to-capture-and-concentrate-solar-energy-the-concentrator-has-several-advantages-over-other-solar-concentrators-including-its-ability-to-reflect-sunlight-from-a-wide-range-of-angles-its-ability-to-concentrate-solar-energy-into-a-small-area-and-its-relatively-easy-manufacture-and-installation-the-concentrator-has-the-potential-to-be-a-cost-effective-option-for-solar-energy-applications",level:2},{value:"tags: hello, docusaurus",id:"tags-hello-docusaurus-5",level:2},{value:"tags: hola, docusaurus",id:"tags-hola-docusaurus-11",level:2},{value:"Docusaurus Plushie",id:"docusaurus-plushie-4",level:2},{value:"tags: hello, docusaurus",id:"tags-hello-docusaurus-6",level:2},{value:"Prepare prices data",id:"prepare-prices-data",level:2},{value:"tags: hello, docusaurus",id:"tags-hello-docusaurus-7",level:2},{value:"Method of Creating an Illusion for an Infinite Universe Utilizing LED Light Strips, Acrylic Sheets, Mirror Film, Half Mirror Film, and Dichroic Film",id:"method-of-creating-an-illusion-for-an-infinite-universe-utilizing-led-light-strips-acrylic-sheets-mirror-film-half-mirror-film-and-dichroic-film",level:2},{value:"Field of the Invention",id:"field-of-the-invention",level:2},{value:"Background",id:"background-1",level:2},{value:"Objective",id:"objective",level:2},{value:"Statements of Invention",id:"statements-of-invention",level:2},{value:"Description of Examples",id:"description-of-examples",level:2},{value:"Customization and Application",id:"customization-and-application",level:2},{value:"sidebar_position: 1",id:"sidebar_position-1",level:2},{value:"sidebar_position: 4",id:"sidebar_position-4",level:2},{value:"sidebar_position: 5",id:"sidebar_position-5",level:2},{value:"Generate list of extensions from existing installation",id:"generate-list-of-extensions-from-existing-installation",level:3},{value:"extensions.md",id:"extensionsmd",level:3},{value:"Install extensions from md file",id:"install-extensions-from-md-file",level:3},{value:"sidebar_position: 3",id:"sidebar_position-3",level:2},{value:"References",id:"references-1",level:2},{value:"sidebar_position: 2",id:"sidebar_position-2",level:2},{value:"References",id:"references-2",level:2},{value:"sidebar_position: 1",id:"sidebar_position-1-1",level:2},{value:"References---",id:"references---",level:2},{value:"sidebar_position: 4",id:"sidebar_position-4-1",level:2},{value:"Install rclone from the package manager",id:"install-rclone-from-the-package-manager",level:3},{value:"Run the rclone configuration wizard to set up a remote storage provider",id:"run-the-rclone-configuration-wizard-to-set-up-a-remote-storage-provider",level:3},{value:"Open the rclone service file in a text editor",id:"open-the-rclone-service-file-in-a-text-editor",level:3},{value:"Add the following content to the service file",id:"add-the-following-content-to-the-service-file",level:3},{value:"Check the status of the rclone service",id:"check-the-status-of-the-rclone-service",level:3},{value:"Start the rclone service immediately",id:"start-the-rclone-service-immediately",level:3},{value:"Enable the rclone service to start at boot",id:"enable-the-rclone-service-to-start-at-boot",level:3},{value:"Reload the system manager configuration",id:"reload-the-system-manager-configuration",level:3},{value:"sidebar_position: 2",id:"sidebar_position-2-1",level:2},{value:"sidebar_position: 3",id:"sidebar_position-3-1",level:2},{value:"sidebar_position: 1",id:"sidebar_position-1-2",level:2},{value:"sidebar_position: 2",id:"sidebar_position-2-2",level:2},{value:"Create a pod",id:"create-a-pod",level:3},{value:"Pull influxdb image",id:"pull-influxdb-image",level:3},{value:"Run image in pod",id:"run-image-in-pod",level:3},{value:"Pull mosquitto image",id:"pull-mosquitto-image",level:3},{value:"Run image in pod",id:"run-image-in-pod-1",level:3},{value:"Generate YAML file",id:"generate-yaml-file",level:3},{value:"Here&#39;s the YAML file",id:"heres-the-yaml-file",level:2},{value:"Test YAML file",id:"test-yaml-file",level:3},{value:"Reference",id:"reference",level:3},{value:"To do",id:"to-do",level:3},{value:"prep seperate usb for firmware",id:"prep-seperate-usb-for-firmware",level:3},{value:"Install CoreOS tools",id:"install-coreos-tools",level:3},{value:"Make working directory and change to it",id:"make-working-directory-and-change-to-it",level:3},{value:"Download CoreOS image",id:"download-coreos-image",level:3},{value:"Rename image to simpler name",id:"rename-image-to-simpler-name",level:3},{value:"Create rpict.bu",id:"create-rpictbu",level:3},{value:"Transpile butane file into an ignition file",id:"transpile-butane-file-into-an-ignition-file",level:3},{value:"Test ignition file in virtual machine",id:"test-ignition-file-in-virtual-machine",level:2},{value:"Setup the correct SELinux label to allow access to the config",id:"setup-the-correct-selinux-label-to-allow-access-to-the-config",level:4},{value:"Start a Fedora CoreOS virtual machine",id:"start-a-fedora-coreos-virtual-machine",level:4},{value:"Exit and destroy virtual machine",id:"exit-and-destroy-virtual-machine",level:4},{value:"Write to disk",id:"write-to-disk",level:3},{value:"Reference",id:"reference-1",level:2},{value:"To do",id:"to-do-1",level:3},{value:"Hardware",id:"hardware",level:3},{value:"Script",id:"script",level:3},{value:"References",id:"references-3",level:2},{value:"sidebar_position: 1",id:"sidebar_position-1-3",level:2},{value:"References",id:"references-4",level:2},{value:"sidebar_position: 1",id:"sidebar_position-1-4",level:2},{value:"Hardware",id:"hardware-1",level:3},{value:"Script",id:"script-1",level:3},{value:"References",id:"references-5",level:2},{value:"sidebar_position: 2",id:"sidebar_position-2-3",level:2},{value:"Hardware",id:"hardware-2",level:3},{value:"Script",id:"script-2",level:3},{value:"References",id:"references-6",level:2},{value:"sidebar_position: 3",id:"sidebar_position-3-2",level:2},{value:"Hardware",id:"hardware-3",level:3},{value:"Script",id:"script-3",level:3},{value:"References",id:"references-7",level:2},{value:"sidebar_position: 2",id:"sidebar_position-2-4",level:2},{value:"Cisco c9800-CL with KVM",id:"cisco-c9800-cl-with-kvm",level:2},{value:"What?",id:"what",level:3},{value:"Install virtualization sowftware group",id:"install-virtualization-sowftware-group",level:3},{value:"Enable libvirtd service",id:"enable-libvirtd-service",level:3},{value:"Create network bridge br10",id:"create-network-bridge-br10",level:2},{value:"Install Virtual Machine",id:"install-virtual-machine",level:2},{value:"If you need to start again, use this to destroy the VM",id:"if-you-need-to-start-again-use-this-to-destroy-the-vm",level:3},{value:"Configure the controller",id:"configure-the-controller",level:3},{value:"Access the GUI",id:"access-the-gui",level:3},{value:"References",id:"references-8",level:2},{value:"sidebar_position: 4",id:"sidebar_position-4-2",level:2},{value:"Steps",id:"steps",level:3},{value:"sidebar_position: 4",id:"sidebar_position-4-3",level:2},{value:"sidebar_position: 4",id:"sidebar_position-4-4",level:2},{value:"sidebar_position: 4",id:"sidebar_position-4-5",level:2},{value:"sidebar_position: 4",id:"sidebar_position-4-6",level:2},{value:"References---",id:"references----1",level:2},{value:"sidebar_position: 7",id:"sidebar_position-7",level:2},{value:"Show column names",id:"show-column-names",level:3},{value:"Show entries in descriptivegroup column",id:"show-entries-in-descriptivegroup-column",level:3},{value:"Show entries in column which match Natural Environment in descriptivegroup column",id:"show-entries-in-column-which-match-natural-environment-in-descriptivegroup-column",level:3},{value:"Show entries in column which match Road in descriptivegroup column",id:"show-entries-in-column-which-match-road-in-descriptivegroup-column",level:3},{value:"Show entries in column which match Building in descriptivegroup column",id:"show-entries-in-column-which-match-building-in-descriptivegroup-column",level:3},{value:"References---",id:"references----2",level:2},{value:"sidebar_position: 3",id:"sidebar_position-3-3",level:2},{value:"Download data",id:"download-data",level:2},{value:"Import bdline",id:"import-bdline",level:2},{value:"Connect to server",id:"connect-to-server",level:2},{value:"SELECT",id:"select",level:3},{value:"Find avarage point value for duplicate polygons",id:"find-avarage-point-value-for-duplicate-polygons",level:2},{value:"Import new price paid polygons to file",id:"import-new-price-paid-polygons-to-file",level:2},{value:"Add price paid polygons layer to Qgis",id:"add-price-paid-polygons-layer-to-qgis",level:2},{value:"Colour polygons by attribute field",id:"colour-polygons-by-attribute-field",level:2},{value:"sidebar_position: 7",id:"sidebar_position-7-1",level:2},{value:"References",id:"references-9",level:2},{value:"sidebar_position: 6",id:"sidebar_position-6",level:2},{value:"Show column names",id:"show-column-names-1",level:3},{value:"Show entries in descriptivegroup column",id:"show-entries-in-descriptivegroup-column-1",level:3},{value:"Show entries in descriptivegroup column",id:"show-entries-in-descriptivegroup-column-2",level:3},{value:"Select scrub land",id:"select-scrub-land",level:3},{value:"References",id:"references-10",level:2},{value:"sidebar_position: 3",id:"sidebar_position-3-4",level:2},{value:"References---",id:"references----3",level:2},{value:"sidebar_position: 3",id:"sidebar_position-3-5",level:2},{value:"Prepare location data",id:"prepare-location-data",level:2},{value:"Import parcels",id:"import-parcels",level:2},{value:"Connect to server",id:"connect-to-server-1",level:2},{value:"set psql password",id:"set-psql-password",level:2},{value:"Create prices table",id:"create-prices-table",level:2},{value:"Create location table",id:"create-location-table",level:2},{value:"Populate prices table",id:"populate-prices-table",level:2},{value:"Populate coordinates table",id:"populate-coordinates-table",level:2},{value:"SELECT",id:"select-1",level:3},{value:"SELECT",id:"select-2",level:3},{value:"Find avarage point value for duplicate polygons",id:"find-avarage-point-value-for-duplicate-polygons-1",level:2},{value:"Import new price paid polygons to file",id:"import-new-price-paid-polygons-to-file-1",level:2},{value:"Add price paid polygons layer to Qgis",id:"add-price-paid-polygons-layer-to-qgis-1",level:2},{value:"Colour polygons by attribute field",id:"colour-polygons-by-attribute-field-1",level:2},{value:"Download data",id:"download-data-1",level:2},{value:"Import bdline",id:"import-bdline-1",level:2},{value:"Connect to server",id:"connect-to-server-2",level:2},{value:"SELECT",id:"select-3",level:3},{value:"Find avarage point value for duplicate polygons",id:"find-avarage-point-value-for-duplicate-polygons-2",level:2},{value:"Import new price paid polygons to file",id:"import-new-price-paid-polygons-to-file-2",level:2},{value:"Add price paid polygons layer to Qgis",id:"add-price-paid-polygons-layer-to-qgis-2",level:2},{value:"Colour polygons by attribute field",id:"colour-polygons-by-attribute-field-2",level:2},{value:"Run image in pod",id:"run-image-in-pod-2",level:3},{value:"auto gen systemd file",id:"auto-gen-systemd-file",level:3},{value:"start postgis service",id:"start-postgis-service",level:3},{value:"enable postgis service",id:"enable-postgis-service",level:3},{value:"Check",id:"check",level:2},{value:"Generate YAML file",id:"generate-yaml-file-1",level:3},{value:"Here&#39;s the YAML file",id:"heres-the-yaml-file-1",level:2},{value:"Test YAML file",id:"test-yaml-file-1",level:3},{value:"Remove postgis container",id:"remove-postgis-container",level:4},{value:"Remove geoserver container",id:"remove-geoserver-container",level:4},{value:"Remove spatial pod",id:"remove-spatial-pod",level:4},{value:"Install everything again using the YAML file",id:"install-everything-again-using-the-yaml-file",level:4},{value:"create table",id:"create-table",level:3},{value:"Import parcels",id:"import-parcels-1",level:3},{value:"Create spatial index",id:"create-spatial-index",level:2},{value:"References",id:"references-11",level:2},{value:"sidebar_position: 4",id:"sidebar_position-4-7",level:2},{value:"To do",id:"to-do-2",level:2},{value:"Install astun loader",id:"install-astun-loader",level:3},{value:"Change directory",id:"change-directory",level:3},{value:"Prepare data",id:"prepare-data",level:3},{value:"Edit loader configuration",id:"edit-loader-configuration",level:3},{value:"Run ashtun loader",id:"run-ashtun-loader",level:3},{value:"Qgis style",id:"qgis-style",level:3},{value:"References",id:"references-12",level:2},{value:"sidebar_position: 5",id:"sidebar_position-5-1",level:2},{value:"Load sattelite data with either raster2pgsql or ogr2ogr",id:"load-sattelite-data-with-either-raster2pgsql-or-ogr2ogr",level:3},{value:"Connect to database",id:"connect-to-database",level:3},{value:"Load sattelite data with either raster2pgsql or ogr2ogr",id:"load-sattelite-data-with-either-raster2pgsql-or-ogr2ogr-1",level:3},{value:"unzip all zips",id:"unzip-all-zips",level:3},{value:"set psql password",id:"set-psql-password-1",level:2},{value:"raster2pgsql",id:"raster2pgsql",level:3},{value:"Add a spatial index",id:"add-a-spatial-index",level:3},{value:"References",id:"references-13",level:2},{value:"sidebar_position: 3",id:"sidebar_position-3-6",level:2},{value:"Load lidar data with either raster2pgsql",id:"load-lidar-data-with-either-raster2pgsql",level:3},{value:"Connect to database",id:"connect-to-database-1",level:3},{value:"Load sattelite data with either raster2pgsql or ogr2ogr",id:"load-sattelite-data-with-either-raster2pgsql-or-ogr2ogr-2",level:3},{value:"unzip all zips",id:"unzip-all-zips-1",level:3},{value:"set psql password",id:"set-psql-password-2",level:2},{value:"raster2pgsql",id:"raster2pgsql-1",level:3},{value:"Add a spatial index",id:"add-a-spatial-index-1",level:3},{value:"References",id:"references-14",level:2},{value:"sidebar_position: 1",id:"sidebar_position-1-5",level:2},{value:"Loop over geojson files and create a new table for each and upload",id:"loop-over-geojson-files-and-create-a-new-table-for-each-and-upload",level:3},{value:"Add a spatial index",id:"add-a-spatial-index-2",level:3},{value:"References",id:"references-15",level:2},{value:"sidebar_position: 1",id:"sidebar_position-1-6",level:2},{value:"Import the necessary modules",id:"import-the-necessary-modules",level:3},{value:"Set the GRASS GIS environment",id:"set-the-grass-gis-environment",level:3},{value:"Import the lidar data into GRASS GIS",id:"import-the-lidar-data-into-grass-gis",level:3},{value:"Identify flat areas by selecting pixels with a slope less than a certain threshold",id:"identify-flat-areas-by-selecting-pixels-with-a-slope-less-than-a-certain-threshold",level:3}],c={toc:d};function p(e){let{components:t,...o}=e;return(0,i.kt)("wrapper",(0,n.Z)({},c,o,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"constructing-a-3d-egg-shape-from-regular-polygons"},"Constructing a 3D Egg Shape from Regular Polygons"),(0,i.kt)("p",null,"As engineers and designers, we are often approached with unusual and challenging requests. One such request came from an artist who asked us to help find a suitable geometry for a large egg sculpture. Intrigued by the opportunity to collaborate with an artist and apply our skills in a creative context, we set out to identify possible geometries using generative algorithms in Grasshopper 3D."),(0,i.kt)("p",null,"The first step in our process was to understand the constraints and requirements of the project. The artist provided us with a set of parameters, including the desired size and shape of the sculpture, as well as the materials that would be used to construct it. With this information in hand, we began to explore different algorithmic approaches that could be used to generate a range of possible geometries."),(0,i.kt)("p",null,"We turned to Grasshopper 3D, a powerful tool for generative design that allows users to define and manipulate geometry through a series of algorithmic rules. Using a combination of mathematical functions and input from the artist, we were able to generate a range of potential geometries for the egg sculpture."),(0,i.kt)("p",null,"To narrow down our options and select the most suitable geometry, we used a variety of methods to evaluate and compare the different options. We considered factors such as structural integrity, ease of fabrication, and aesthetic appeal, and used computer simulations and physical prototypes to test the performance of the different geometries."),(0,i.kt)("p",null,"In the end, we were able to identify a geometry that met all of the requirements and constraints of the project. The artist was pleased with the result and used our geometry to create a stunning egg sculpture that was well-received by the public."),(0,i.kt)("p",null,"This project was a rewarding and exciting example of the ways in which engineering and design can intersect with the arts. By using generative algorithms and a collaborative approach, we were able to help an artist realize their vision and create a beautiful work of art."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(8185).Z,width:"655",height:"527"})),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(1434).Z,width:"1209",height:"512"}),"---\nslug: designing-hardware-for-mounting-wireless-hardware-equiptment-on-marquees\ntitle:  Designing Hardware for Mounting Wireless Equipment on Marquees\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus"},"tags: ","[hola, docusaurus]"),(0,i.kt)("h1",{id:"designing-hardware-for-mounting-wireless-equipment-on-marquees"},"Designing Hardware for Mounting Wireless Equipment on Marquees"),(0,i.kt)("p",null,"Wireless access points and point-to-point links have been installed on the aluminum extrusion structural elements of outdoor event marquees using a innovative system that employs a keeder rail. The keeder rail accommodates a cylindrical metal piece with a threaded hole drilled perpendicular to its length, which can be easily secured in place by turning a large, flat disk with a threaded hole in the center. This setup supports a pipe clamp that is designed to fit standard aluminum poles, with two clamps used per pole to securely anchor the pole vertically on the side of the tent. This innovative method of installation allows for reliable and secure connectivity during events, while also maintaining the aesthetic integrity of the marquees."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(7451).Z,width:"4032",height:"3024"})),(0,i.kt)("h2",{id:"docusaurus-plushie"},(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(7332).Z,width:"3120",height:"4160"})),(0,i.kt)("p",null,"slug: wireless-coverage-at-manchester-pride\ntitle: Wireless Coverage at Manchester Pride - A Heatmap Analysis\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus-1"},"tags: ","[hola, docusaurus]"),(0,i.kt)("h1",{id:"wireless-coverage-at-manchester-pride---a-heatmap-analysis"},"Wireless Coverage at Manchester Pride - A Heatmap Analysis"),(0,i.kt)("p",null,"As part of this deployment project, our team encountered a physically demanding challenge: the installation of two sectors on the 18th floor of a tower block adjacent to the event site. From this vantage point, we were able to transmit a strong signal to multiple wireless point-to-point stations attached to temporary structures and buildings within the site. Additionally, we provided indoor wireless coverage in an underground parking garage that served as one of the event venues. To ensure optimal coverage, we created a heat map of the wireless signal strength in this area. Moreover, we established uplinks at various locations throughout the site to support ticket booths, CCTV cameras, payment terminals for bars, a production office, and emergency liaison cabins. Overall, this comprehensive approach to wireless connectivity allowed for seamless communication and connectivity throughout the event.---\nslug: exploring-the-unique-characteristics-of-natural-building-materials\ntitle: Exploring the Unique Characteristics of Natural Building Materials\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus-2"},"tags: ","[hola, docusaurus]"),(0,i.kt)("h1",{id:"exploring-the-unique-characteristics-of-natural-building-materials"},"Exploring the Unique Characteristics of Natural Building Materials"),(0,i.kt)("p",null,"Inspired by the idea of using natural building materials, we set out to explore the unique characteristics and personalities of each material and use them in innovative ways in our design. We wanted to capture the mood and atmosphere of the natural environments where these materials are typically found, such as the underground world of stone and water or the airy heights of wood."),(0,i.kt)("p",null,"To this end, we experimented with lightweight hazel structures as a way to combine wood and air in our design. We were particularly interested in the underground world of stone and water, and decided to dig a tunnel into the side of a hill to see what we could discover. Unfortunately, the largest cavity we found was only two feet wide, and we had to come up with a different solution to support the roof of the tunnel. We ended up building concrete block load-bearing walls with concrete lintels supporting the stone above, which took up a lot of space and lost some of the rustic charm of our original design, but was necessary for safety."),(0,i.kt)("p",null,"According to our cross-sectional diagram, there is a third layer between the stone and wood in our design - a thin layer of mud from which all life springs. While we have not yet conducted extensive research on using mud as a building material, we have done extensive research and design work on the organic life that it can support. In our design, we envision the wood as the ideal location for sleeping quarters, warm and dry in the loft, while the ground floor would be reserved for the kitchen, toilet, and other organic activities, including food production. There may also be some kind of underground stone cavernous space beneath the building for an as-yet-unknown purpose."),(0,i.kt)("p",null,"Overall, our goal in this project was to use natural building materials in unique and innovative ways that captured the mood and atmosphere of the natural environments where these materials are typically found. While we encountered some challenges along the way, the process was exciting and rewarding, and we are proud of the design we have created.---\nslug: vertical-farming-for-continuous-salad-production\ntitle: Vertical Farming for Continuous Salad Production\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus-3"},"tags: ","[hola, docusaurus]"),(0,i.kt)("h1",{id:"vertical-farming-for-continuous-salad-production"},"Vertical Farming for Continuous Salad Production"),(0,i.kt)("p",null,"Our team has an innovative idea for a self-sustaining salad bar that utilizes vertical space to meet production needs. We propose planting seedlings in a steel cable reinforced fiber matting that hangs vertically above the counter. This matting would be supported by two large drums at the top and bottom, and would be able to rotate at a speed calculated based on the height of the assembly, the maturation time of the chosen crop, and the desired harvesting frequency. This way, a seedling planted at the bottom would be ready for harvest by the time it reaches the top and returns to the bottom. With this system, the salad bar would be able to achieve perpetual harvesting, meeting its demand for fresh produce without having to rely on traditional terrestrial agriculture methods."),(0,i.kt)("p",null,"In addition to this innovative planting system, we also propose supplying the plants with dissolved nutrients by producing an ultrasonic fog in the chamber between the two planting surfaces. This would help to ensure that the plants have all the nutrients they need to grow and thrive. To maintain a stable temperature for the plants, we suggest using a vertical poly tunnel in colder climates to protect them from temperature fluctuations."),(0,i.kt)("p",null,"Overall, our self-sustaining salad bar concept would be a revolutionary way to meet the demand for fresh produce in a sustainable and efficient manner. By utilizing vertical space and innovative technologies, we believe this concept has the potential to revolutionize the way that salad bars and other food establishments source their produce.---\nslug: designing-a-living-building:-an-organism-with-a-symbiotic-relationship-with-its-occupants\ntitle: Designing a Living Building - An Organism with a Symbiotic Relationship with Its Occupants\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus-4"},"tags: ","[hola, docusaurus]"),(0,i.kt)("h1",{id:"designing-a-living-building-an-organism-with-a-symbiotic-relationship-with-its-occupants"},"Designing a Living Building: An Organism with a Symbiotic Relationship with Its Occupants"),(0,i.kt)("p",null,"When designing a building, it is important to consider the building as an organism that has a symbiotic relationship with its occupants. This means that the building should be organized like a system of interdependent organisms, with each organism fulfilling a specific function within the larger structure. By treating the building as an organism, we can create a dynamic and self-sustaining ecosystem that supports the health and well-being of its occupants."),(0,i.kt)("p",null,"There are many different types of organisms that can be incorporated into the design of a building. Some examples might include microalgae, which can be used for wastewater treatment and oxygen production; vermiculture, which can be used for composting and soil improvement; fish, which can be used for food production and waste management; guinea pigs, which can be used for research and education; leafy green plants, which can be used for air purification and aesthetics; and bacteria, which can be used for biological processes such as fermentation and nutrient cycling."),(0,i.kt)("p",null,"The building itself should function like a shell or frame that provides a home for these organisms. By using environment-specific creatures, it is possible to keep different systems separate, creating an urban jungle inside the building. This approach allows for the creation of a diverse and self-sustaining ecosystem within the building, providing numerous benefits to the occupants such as improved air quality, food production, and waste management. By considering the building as an organism with a symbiotic relationship with its occupants, we can design buildings that are more dynamic, self-sustaining, and supportive of human health and well-being.---\nslug: designing-for-comfort-and-practicality-in-motor-caravans\ntitle: Designing for Comfort and Practicality in Motor Caravans\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hello-docusaurus"},"tags: ","[hello, docusaurus]"),(0,i.kt)("h1",{id:"designing-for-comfort-and-practicality-in-motor-caravans"},"Designing for Comfort and Practicality in Motor Caravans"),(0,i.kt)("p",null,"As engineers and designers, it is our duty to create structures that not only function well, but also enhance the lives of those who use them. This is particularly important in the design of motor caravans, which serve as both vehicles and living spaces for travelers. With this in mind, we set out to design a caravan that prioritized both comfort and practicality."),(0,i.kt)("p",null,"The first step in our process was to choose the most suitable materials and construction techniques. We decided to use a thick layer of spray foam as the foundation for the caravan's shape, which was then carved back to the desired form and rendered with acrylic putty. This method allowed us to create a strong and lightweight structure, while also providing excellent insulation to keep the interior comfortable."),(0,i.kt)("p",null,"Next, we focused on the layout of the interior space. We installed a single bed lengthways, with a desk running parallel to it. This arrangement allowed for maximum use of the limited space, while also providing a comfortable and functional sleeping and working area. In addition, we designed the layout in such a way that the user can easily walk from the back of the caravan to the side door unhindered, which gives flexibility in terms of access and egress."),(0,i.kt)("p",null,"To ensure practicality, we also included a bulkhead kitchen with a water-saving faucet, a full-size fridge, and a hob. These features allow the user to easily prepare meals and store food while on the road. We also installed double-layered Ikea blackout blinds and windows all around to provide privacy and regulate light and temperature within the caravan."),(0,i.kt)("p",null,"Overall, our design for this motor caravan prioritizes both comfort and practicality, making it an ideal living space for travelers. By carefully considering the materials, layout, and features, we have created a functional and enjoyable space that will enhance the experience of those who use it."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(9766).Z,width:"950",height:"531"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(1402).Z,width:"950",height:"531"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(5660).Z,width:"950",height:"531"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(3692).Z,width:"950",height:"531"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(7392).Z,width:"950",height:"531"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(3739).Z,width:"950",height:"531"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(4963).Z,width:"746",height:"526"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(8849).Z,width:"746",height:"526"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(9718).Z,width:"746",height:"526"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(6124).Z,width:"746",height:"526"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(6226).Z,width:"746",height:"526"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(7833).Z,width:"746",height:"526"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(6797).Z,width:"746",height:"526"}),"---\nslug: wireless-coverage-at-the-bath-festival-a-heatmap-analasis\ntitle: Wireless Coverage at the Bath Festival - A Heatmap Analysis\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus-5"},"tags: ","[hola, docusaurus]"),(0,i.kt)("h1",{id:"wireless-coverage-at-the-bath-festival---a-heatmap-analysis"},"Wireless Coverage at the Bath Festival - A Heatmap Analysis"),(0,i.kt)("p",null,"At the Bath Festival, a small deployment of access points was placed around the tents to provide WiFi connectivity to attendees. In order to maximize coverage and ensure reliable connectivity, each access point was connected to a sector on an adjacent building via a point-to-point wireless link. In addition to the wireless link, each access point was also connected to a ADSL line and a temporary satellite on the roof to provide multiple redundant Internet connections."),(0,i.kt)("p",null,"To assess the performance of the access points and identify any areas with weak signal strength or wireless black spots, we used an Android app to collect a series of geolocated signal strength data points. These data points were formatted in Excel and then uploaded into ArcGIS, where a tool was used to create a heat map. This heat map was then overlayed over the site plan to provide a visual representation of the signal strength across the festival grounds."),(0,i.kt)("p",null,"By collecting and analyzing this data, we were able to identify any areas with weak signal strength or wireless black spots and take steps to improve coverage in these areas. This ensured that attendees were able to access the WiFi network and stay connected throughout the duration of the festival. By using a combination of a point-to-point wireless link, a ADSL line, and a temporary satellite, we were able to provide reliable and redundant Internet connectivity to the festival attendees.---\nslug: using-data-queries-to-enhance-wildlife-connectivity\ntitle: Using Data Queries to Enhance Wildlife Connectivity\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hello-docusaurus-1"},"tags: ","[hello, docusaurus]"),(0,i.kt)("h1",{id:"using-data-queries-to-enhance-wildlife-connectivity"},"Using Data Queries to Enhance Wildlife Connectivity"),(0,i.kt)("p",null,'Rewilding involves the restoration of natural habitats in areas that have been modified or degraded by human activity. One way to identify suitable areas for rewilding is to search for topographic areas that are characterized by natural environments. This can be achieved through the use of a SQL query to search for rows in a database table where the value "Natural Environment" appears in the "descriptivegroup" column. This column likely contains an array of descriptive tags or categories for each topographic area.'),(0,i.kt)("p",null,"The results of this query can inform planning and conservation efforts by identifying areas that are potentially well-suited for rewilding. These areas could provide corridors for wildlife movement through urban environments and enhance biodiversity in these areas. By prioritizing these areas for restoration and rewilding, it is possible to improve the connectivity of natural habitats in urban areas and promote the health and well-being of these ecosystems."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT *\nFROM topographicarea\nWHERE 'Natural Environment' = ANY (descriptivegroup)\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(7792).Z,width:"1515",height:"779"})),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(7792).Z,width:"1515",height:"779"})),(0,i.kt)("p",null,"You can see how the edges or roads and railway tracs could be used as wildlife corridors."),(0,i.kt)("h2",{id:"docusaurus-plushie-1"},(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(1094).Z,width:"1515",height:"779"})),(0,i.kt)("p",null,"slug: live-network-map-for-womad-festival\ntitle: Live Network Map for WOMAD Festival - Visualizing Status and Coverage\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hello-docusaurus-2"},"tags: ","[hello, docusaurus]"),(0,i.kt)("h1",{id:"live-network-map-for-womad-festival---visualizing-status-and-coverage"},"Live Network Map for WOMAD Festival - Visualizing Status and Coverage"),(0,i.kt)("p",null,"The web application we developed allows users to access and update the location data for network devices. When the location of a device needs to be recorded, the user simply enters the device's MAC address into the app. The MAC address is then checked against a list of available device MAC addresses in the database to verify its authenticity. If the MAC address exists in the database, it is marked as \"deployed\" and the coordinates of the user's phone, on which the update was made, are added to the latitude and longitude columns. If the MAC address is entered incorrectly or does not correspond to a device in the database, the app user is notified and asked to enter a different MAC address."),(0,i.kt)("p",null,'The deployed devices are displayed on a map in real-time, allowing users to easily view and locate them. Each device can be clicked on to view information such as its device type, MAC address, IP address, and more. Users also have the option to select a device for deletion, which changes the corresponding value in the "deployment status" column to "false" and removes the latitude and longitude position values from the database.'),(0,i.kt)("p",null,"To aid in testing and debugging the app, we also developed a BASH script that produces fake data for testing purposes. This script generates a CSV file containing random MAC addresses, asset tags, device models, and locations, which can then be uploaded to the database for testing purposes. By using this script, we were able to simulate different scenarios and ensure that the app was functioning correctly before deploying it in a live environment."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'#!/bin/bash\n\n# Generate 100 random devices\nfor i in {1..100}\ndo\n  # Generate a random MAC address\n  mac=$(c=0; until [ $c -eq "6" ]; do printf ":%02X" $(( $RANDOM % 256 )); let c=c+1; done | sed s/://)\n\n  # Generate a random asset number\n  asset=$(( $RANDOM % 9999 + 1000 ))\n\n  # Choose a random location from the locations.txt file\n  location=$(shuf -n 1 locations.txt)\n\n  # Choose a random model from the models.txt file\n  model=$(shuf -n 1 models.txt)\n\n  # Output the device information to a CSV file\n  echo "$asset, $mac, $model, $location"\ndone > devices.csv\n')),(0,i.kt)("hr",null),(0,i.kt)("p",null,"slug: mapping-wireless-coverage-at-the-royal-windsor-horse-show-with-arcgis\ntitle: Mapping Wireless Coverage at the Royal Windsor Horse Show with ArcGIS\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus-6"},"tags: ","[hola, docusaurus]"),(0,i.kt)("h1",{id:"mapping-wireless-coverage-at-the-royal-windsor-horse-show-with-arcgis"},"Mapping Wireless Coverage at the Royal Windsor Horse Show with ArcGIS"),(0,i.kt)("p",null,"The Royal Windsor Horse Show is an annual event that attracts thousands of visitors and is the largest outdoor horse show in the United Kingdom. In order to ensure that the event runs smoothly, it is important to provide reliable connectivity to the staff and trader areas."),(0,i.kt)("p",null,"To achieve this, our team deployed a wireless network on the show grounds and created a heat map by taking geolocated signal strength readings on a smartphone from all over the site. This data was then uploaded into ArcGIS and used to create a heat map, which highlighted areas with weak signal strength or wireless black spots."),(0,i.kt)("p",null,"To help visualize the network and identify any potential issues, the heat map was overlaid on a georeferenced site map that showed the locations of wireless access points, cable routes, and network switch locations. By using this information, we were able to ensure that the staff and trader areas had the necessary connectivity to support the needs of the event."),(0,i.kt)("p",null,"Overall, the deployment of the wireless network at the Royal Windsor Horse Show was a success and played a vital role in the smooth running of the event. We are proud to have been able to support the needs of the staff and traders and help make the event a success."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(5670).Z,width:"1034",height:"633"})),(0,i.kt)("hr",null),(0,i.kt)("p",null,"slug: tracking-network-hardware-assets-at-the-isle-of-wight-festival\ntitle: Tracking Network Hardware Assets at the Isle of Wight Festival\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hello-docusaurus-3"},"tags: ","[hello, docusaurus]"),(0,i.kt)("h1",{id:"tracking-network-hardware-assets-at-the-isle-of-wight-festival"},"Tracking Network Hardware Assets at the Isle of Wight Festival"),(0,i.kt)("p",null,"The Isle of Wight Festival 2019 was a large-scale event that took place at Seaclose Park on the Isle of Wight. With 3km of arenas and fields to cover, the deployment of the network was a massive and complex undertaking. To ensure that the site was properly connected, network cabinets were set up in each arena and connected with miles of fiber optic cable. These cabinets were then connected to multiple ADSL connections that were bonded together, providing a robust and reliable internet connection."),(0,i.kt)("p",null,"To provide connectivity within each arena, smaller network switches were located within 100m of the cabinets. Locations that were beyond this range were connected with wireless point-to-point links, which were either mounted on poles attached to the sides of tents or beam out across the arena from wireless sectors mounted on cherry pickers. These signals were then picked up at distant locations through wireless point-to-point receivers attached to the sides of tents."),(0,i.kt)("p",null,"In addition to the network infrastructure, the event also required a comprehensive CCTV system to ensure the safety of attendees. To this end, at least one cherry picker equipped with a pan-tilt-zoom CCTV camera was stationed within each arena, with additional cameras installed on scaffolding poles, gateway arches, and stage sides. WiFi was also provided in the crew and camping areas, and temporary offices were equipped with temporary WiFi and VoIP phones for both internal and external communication."),(0,i.kt)("p",null,"To aid in the deployment and management of the network, we utilized a number of tools and resources. For example, we used QGIS's 'Align Raster' tool to georeference a high-definition image of the site map, which we then uploaded to Mapbox and used to create a basic Leaflet.js web map. This map used the host phone's geolocation to position a marker, helping us to determine our exact location on the site and identify which tents required connectivity. We also used the 'Map Marker' app on Android to quickly locate network devices as we deployed them."),(0,i.kt)("p",null,"After the event, the map was used to quickly locate and retrieve all of the equipment. This was particularly useful as the staff members who investigate faults or retrieve hardware after an event are often different from those who deployed it, making it difficult to locate the devices without a detailed and up-to-date map showing their locations and connections. By using this map, we were able to efficiently trace faults in the network and ensure that all of the equipment was properly accounted for. Overall, the deployment and management of the network at the Isle of Wight Festival was a successful and complex endeavor that helped to ensure the smooth operation of the event."),(0,i.kt)("hr",null),(0,i.kt)("p",null,"slug: provisioning-cisco-cloud-wireless-controller\ntitle: Provisioning Cisco Cloud Wireless Controller\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus-7"},"tags: ","[hola, docusaurus]"),(0,i.kt)("h1",{id:"provisioning-cisco-cloud-wireless-controller"},"Provisioning Cisco Cloud Wireless Controller"),(0,i.kt)("p",null,"In this project, we aimed to successfully install and configure the Cisco Catalyst c9800-CL wireless controller using KVM (Kernel-based Virtual Machine). The c9800-CL is a powerful and flexible cloud-based wireless controller that is capable of managing both on-premises and cloud-based wireless networks. It belongs to the Cisco Catalyst 9800 series and offers a range of advanced features such as wireless intrusion prevention, location services, and guest access."),(0,i.kt)("p",null,"To begin, we installed virtualization software and enabled the libvirtd service on our system. This allowed us to create and manage virtual machines using KVM. We then created a network bridge using the brctl command, which enabled communication between the virtual machine and the host system."),(0,i.kt)("p",null,"With the necessary infrastructure in place, we used the virt-install command to install the c9800-CL on a new virtual machine. During the installation process, we specified a number of options such as the connection to the virtualization server, the operating system variant, the architecture of the virtual machine, and the CPU type."),(0,i.kt)("p",null,"Once the virtual machine was set up and the c9800-CL was installed, we provided a script to configure the controller. This script contained a series of steps that were necessary to properly set up the c9800-CL. These steps included setting the hostname, creating a user account, configuring the Gigabit Ethernet interfaces, creating a VLAN, setting up static routes, shutting down and re-enabling the radio frequencies, and setting the country code. We also configured the virtual wireless LAN controller (VWLC) and set the DNS and NTP servers to ensure proper network connectivity and synchronization."),(0,i.kt)("p",null,"Finally, we demonstrated how to access the GUI of the c9800-CL at the specified IP address and walk through the zero-day configuration steps to set up a wireless network. By following these steps, users can easily configure the c9800-CL to meet the specific needs of their wireless network.---\nslug: creating-3d-buildings-from-mastermap-with-qgis\ntitle: Creating 3d Buildings From Mastermap With Qgis\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus-8"},"tags: ","[hola, docusaurus]"),(0,i.kt)("h1",{id:"creating-3d-buildings-from-mastermap-with-qgis"},"Creating 3d Buildings From Mastermap With Qgis"),(0,i.kt)("p",null,"The Ordnance Survey Mastermap Topography Layer, the Building Height Attribute (BHA), and the Environment Agency LiDAR Digital Terrain Model (DTM) are all useful data sources that can be used to create 3D models of buildings. By combining this data and using the Qgis2ThreeJS plugin in QGIS, it is possible to visualize the BHA data in 3D and create a 3D model of a building."),(0,i.kt)("p",null,"To do this, the Qgis2ThreeJS plugin must be installed and the BHA data, DTM data, and any additional desired layers must be loaded into the QGIS project. The plugin can then be used to style the BHA data and specify the desired height attribute for extrusion, resulting in a 3D model of the building. This model can be saved as an HTML file and viewed in a web browser."),(0,i.kt)("p",null,"When combined with the LiDAR DTM, the resulting 3D model is fairly accurate and can be opened in Grasshopper, a visual programming language and environment that runs within the Rhinoceros 3D CAD application. With the addition of the Ladybug plugin, this 3D model can be used to perform detailed analyses of climate data and create customized, interactive visualizations for environmentally-informed design, such as sunlight studies."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(8640).Z,width:"849",height:"519"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(145).Z,width:"849",height:"519"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(450).Z,width:"849",height:"519"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(2040).Z,width:"849",height:"519"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(7616).Z,width:"849",height:"519"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(74).Z,width:"849",height:"519"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(5147).Z,width:"849",height:"519"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(4945).Z,width:"849",height:"519"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(5829).Z,width:"849",height:"519"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(1726).Z,width:"849",height:"519"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(8855).Z,width:"849",height:"519"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(9947).Z,width:"1288",height:"605"})),(0,i.kt)("h1",{id:"references"},"References"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://digimap.edina.ac.uk/help/gis/qgis/qgis_bha/"},"qgis bha")),(0,i.kt)("hr",null),(0,i.kt)("p",null,"slug: gifford-circus-cry-wheel-performances\ntitle: Gifford Circus Cyr Wheel Performances - A Custom Modular Circular Stage\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus-9"},"tags: ","[hola, docusaurus]"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(9076).Z,width:"1018",height:"1064"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(5800).Z,width:"1041",height:"773"})),(0,i.kt)("h1",{id:"gifford-circus-cyr-wheel-performances---a-custom-modular-circular-stage"},"Gifford Circus Cyr Wheel Performances - A Custom Modular Circular Stage"),(0,i.kt)("p",null,"We were commissioned to design and construct a circular stage for a Cyr wheel performance in Gifford's Circus. The stage had to meet several requirements: it had to have a diameter of 6 meters, be able to be disassembled into pieces small enough to fit through a door with a width of 2.6 meters, be able to support the weight of performers, be easy to assemble by two people in a short amount of time (with each panel weighing no more than 50kg), be flat and level on rough ground, and be durable enough to withstand the rough handling and moisture of circus life."),(0,i.kt)("p",null,"To achieve these goals, we considered various designs for the circle and ultimately settled on a composite panel made of an XPS core sandwiched between two layers of extra durable fibreglass, with a non-slip coating. The material was cut into the necessary shapes using a hot wire cutter with a rectangular profile, and the foam was removed from the mating edges, leaving only the outer fibreglass material. Adhesive was applied and aluminum extrusion was pressed into the edges of the panels. The aluminum provided protection for the edges, supported the edges to prevent deflection, and provided slots for the removable leg structures that connected the panels together."),(0,i.kt)("p",null,"The leg structures were placed at the intersection of three panels and consisted of three pieces of steel box section fitted within aluminum U channels and welded at 120-degree increments to form a three-directional cross. A hole was left at the intersection, into which a threaded tube was welded. An internal hex bolt or long grub screw with a foot plate on the bottom was threaded into the tube and could be adjusted from above through a small hole in the stage using an allen key bit on an impact driver. This arrangement allowed for a quick and easy assembly process, with the legs being extended until they touched the ground to level the stage. The pieces were held together with inner steel box sections curved on the outer curved edges, and a large ratchet strap was used to wrap around the entire structure and compress the circle inward, pulling all the pieces together."),(0,i.kt)("p",null,"Overall, the design and construction of the circular stage was a challenging but rewarding project. We were able to meet all of the requirements set forth by the client and create a stage that was durable, stable, and easy to assemble and transport. "),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(3542).Z,width:"1041",height:"773"})),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(7139).Z,width:"1058",height:"752"}),"\n",(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(3013).Z,width:"1011",height:"769"})),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(2323).Z,width:"1059",height:"832"})),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(380).Z,width:"985",height:"1547"})),(0,i.kt)("h2",{id:"docusaurus-plushie-2"},(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(6219).Z,width:"861",height:"1302"})),(0,i.kt)("p",null,"slug: truss-connection-node-modeling\ntitle:  Truss Connection Node Modeling\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus-10"},"tags: ","[hola, docusaurus]"),(0,i.kt)("h1",{id:"truss-connection-node-modeling"},"Truss Connection Node Modeling"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(9173).Z,width:"573",height:"324"})),(0,i.kt)("p",null,"In this project, we designed and fabricated a dodecahedron-shaped structural node for use in a truss system. A truss is a structural element that consists of a series of interconnected struts, which work together to distribute loads evenly and maintain the stability and strength of the structure. The node we created had 12 pentagonal faces, and each truss strut was attached to the center of one of these faces via a single bolt. This bolt passed through a hole in the center of the end cap of the strut and was secured in place by screwing it into a threaded hole in the center of the dodecahedron face."),(0,i.kt)("p",null,"The node was made of steel and was designed to resist the forces transmitted through the truss. Its dodecahedron shape and the use of a single bolt per strut allowed for a high level of flexibility and adaptability, as the struts could be easily rearranged or removed due to their modular design. This feature made the node a crucial element in the overall design of the truss, as it enabled the structure to be easily modified or altered to meet changing needs or requirements."),(0,i.kt)("p",null,"Overall, the dodecahedron-shaped structural node we created proved to be an effective and efficient solution for joining multiple truss struts together at a single point. It played a vital role in distributing loads evenly and maintaining the stability and strength of the truss, and its modular design allowed for flexibility and adaptability in the overall structure."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(8997).Z,width:"476",height:"442"})),(0,i.kt)("h2",{id:"docusaurus-plushie-3"},(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(2842).Z,width:"4592",height:"3448"})),(0,i.kt)("p",null,"slug: modeling-a-spherical-solar-concentrator\ntitle: Modeling a Spherical Solar Concentrator\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hello-docusaurus-4"},"tags: ","[hello, docusaurus]"),(0,i.kt)("h1",{id:"modeling-a-spherical-solar-concentrator"},"Modeling a Spherical Solar Concentrator"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(2078).Z,width:"718",height:"521"})),(0,i.kt)("p",null,"If a mirror is positioned on the surface of a sphere and is perpendicular to a line that extends from the center of the sphere to a point on the surface of the sphere, light from outside the sphere that is directed towards the mirror will be reflected off the mirror's surface and into the center of the sphere."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(5158).Z,width:"4592",height:"3448"})),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(8921).Z,width:"1700",height:"1610"})),(0,i.kt)("h2",{id:"background"},"Background"),(0,i.kt)("p",null,"Solar energy is a renewable energy source that has the potential to meet a significant portion of the world's energy needs. However, solar energy is currently not as widely used as other energy sources due to the difficulty of capturing and concentrating solar energy."),(0,i.kt)("h2",{id:"abstract"},"Abstract"),(0,i.kt)("p",null,"A solar concentrator is provided that uses a sphere with rotating mirrors to concentrate solar energy. The sphere is covered with a plurality of small mirrors, each of which can rotate freely in any direction. Light from outside the sphere that is directed towards any of the mirrors will be reflected off the mirror's surface and into the center of the sphere. The concentrated solar energy can then be used to generate electricity or heat water."),(0,i.kt)("h2",{id:"description"},"Description"),(0,i.kt)("p",null,"The solar concentrator comprises a sphere, a plurality of small mirrors, and a support structure. The sphere is covered with the plurality of small mirrors, each of which can rotate freely in any direction. The support structure supports the sphere and maintains it in a fixed position."),(0,i.kt)("p",null,"The small mirrors can be made of any material that is reflective of sunlight, such as glass, metal, or plastic. The support structure can be made of any material that is strong enough to support the weight of the sphere and that will not corrode in sunlight."),(0,i.kt)("p",null,"The solar concentrator can be used to generate electricity or heat water. To generate electricity, the concentrated solar energy can be used to heat a fluid, such as water or molten salt. The heated fluid can then be used to drive a turbine, which can generate electricity. To heat water, the concentrated solar energy can be used to heat water directly. The heated water can then be used for bathing, cooking, or other purposes."),(0,i.kt)("h2",{id:"advantages"},"Advantages"),(0,i.kt)("p",null,"The solar concentrator using a sphere with rotating mirrors has several advantages over other solar concentrators. First, the rotating mirrors are able to reflect sunlight from a wide range of angles, which makes it more efficient at capturing solar energy. Second, the rotating mirrors are able to concentrate solar energy into a small area, which makes it more efficient at generating electricity or heating water. Third, the rotating mirrors are relatively easy to manufacture and install, which makes it a cost-effective option for solar energy applications."),(0,i.kt)("h2",{id:"claims"},"Claims"),(0,i.kt)("p",null,"A solar concentrator comprising:\na sphere;\na plurality of small mirrors; and\na support structure.\nThe sphere is covered with the plurality of small mirrors, each of which can rotate freely in any direction.\nThe support structure supports the sphere and maintains it in a fixed position.\nThe small mirrors are made of a material that is reflective of sunlight.\nThe support structure is made of a material that is strong enough to support the weight of the sphere and that will not corrode in sunlight.\nThe solar concentrator is used to generate electricity.\nThe solar concentrator is used to heat water."),(0,i.kt)("h2",{id:"conclusion"},"Conclusion"),(0,i.kt)("h2",{id:"the-solar-concentrator-using-a-sphere-with-rotating-mirrors-is-a-novel-and-efficient-way-to-capture-and-concentrate-solar-energy-the-concentrator-has-several-advantages-over-other-solar-concentrators-including-its-ability-to-reflect-sunlight-from-a-wide-range-of-angles-its-ability-to-concentrate-solar-energy-into-a-small-area-and-its-relatively-easy-manufacture-and-installation-the-concentrator-has-the-potential-to-be-a-cost-effective-option-for-solar-energy-applications"},"The solar concentrator using a sphere with rotating mirrors is a novel and efficient way to capture and concentrate solar energy. The concentrator has several advantages over other solar concentrators, including its ability to reflect sunlight from a wide range of angles, its ability to concentrate solar energy into a small area, and its relatively easy manufacture and installation. The concentrator has the potential to be a cost-effective option for solar energy applications."),(0,i.kt)("p",null,"slug: parish-house-prices\ntitle: Parish House Prices - A Map of Average Sale Prices\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hello-docusaurus-5"},"tags: ","[hello, docusaurus]"),(0,i.kt)("h1",{id:"parish-house-prices---a-map-of-average-sale-prices"},"Parish House Prices - A Map of Average Sale Prices"),(0,i.kt)("p",null,"In order to accurately assess the real estate market, our team utilized property sale data from the land registry and postal code data from the Ordnance Survey to determine the latitude and longitude coordinates of each house sale. This data was then imported into a PostGIS database, where an SQL query was run to calculate the average home price for each parish. To facilitate the visualization and analysis of this information, we utilized the powerful mapping software QGIS. By coloring the polygons representing each parish based on the average price, we were able to clearly and intuitively display the variations in the housing market across the region."),(0,i.kt)("p",null,"This process allowed us to gain a detailed and nuanced understanding of the real estate market, and to identify trends and patterns that would not have been immediately apparent without the use of spatial analysis. By combining the robust data management capabilities of PostGIS with the intuitive mapping capabilities of QGIS, we were able to effectively and efficiently analyze complex data sets and extract valuable insights."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(2198).Z,width:"1630",height:"886"}),"---\nslug: flood-risk-assessment-of-pudding-brook\ntitle: Flood Risk Assessment of Pudding Brooke\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hola-docusaurus-11"},"tags: ","[hola, docusaurus]"),(0,i.kt)("h1",{id:"flood-risk-assessment-of-pudding-brooke"},"Flood Risk Assessment of Pudding Brooke"),(0,i.kt)("p",null,"In order to assess the flood risk of Pudding Brooke, we first imported Digital Terrain Model LIDAR tiles into QGIS and used them to create contour polygons at 0.25m intervals. These contour polygons were then styled using a graduated color scheme, with each polygon being colored based on its elevation. This allowed us to easily visualize the topography of the area and identify areas that were prone to flooding."),(0,i.kt)("p",null,"After creating the contour polygons, we selected potential sites for outbuildings in appropriate high ground locations. This was an important step in the flood risk assessment process, as we needed to ensure that any new structures that were built would be situated on high ground and therefore less vulnerable to flooding. To identify suitable locations for outbuildings, we carefully evaluated the contour polygons and selected sites that were located on the highest ground available."),(0,i.kt)("p",null,"Overall, the use of Digital Terrain Model LIDAR tiles and contour polygons was essential in helping us to accurately assess the flood risk of Pudding Brooke and identify suitable sites for outbuildings. By carefully analyzing the topography of the area, we were able to make informed decisions about where it was safe to build, ensuring that any new structures would be protected from potential flooding."),(0,i.kt)("h2",{id:"docusaurus-plushie-4"},(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(8304).Z,width:"1112",height:"577"})),(0,i.kt)("p",null,"slug: inspire-index-polygon-house-prices\ntitle: INSPIRE Index Polygon House Prices - A Map of Average Sale Prices\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hello-docusaurus-6"},"tags: ","[hello, docusaurus]"),(0,i.kt)("h1",{id:"inspire-index-polygon-house-prices---a-map-of-average-sale-prices"},"INSPIRE Index Polygon House Prices - A Map of Average Sale Prices"),(0,i.kt)("h2",{id:"prepare-prices-data"},"Prepare prices data"),(0,i.kt)("p",null,'In order to effectively analyze and visualize real estate data, it is important to first properly organize and process the data. To this end, our team combined three separate files containing price paid data into a single file and cleaned and filtered the data through a series of steps. These steps included the removal of quotes, the selection of only rows with "GL" followed by a number, the printing of certain columns, the addition of column names, and the deletion of rows with null values.'),(0,i.kt)("p",null,"Once the data was cleaned and organized, we used the powerful tool ogr2ogr to convert a file with cadastral parcel information into a PostgreSQL file. We then changed the projection from OSGB to WGS84 and imported it into a database. In order to store the data in a structured manner, we started a psql session and created empty tables with certain columns in the database."),(0,i.kt)("p",null,"Next, we used the \\copy command and SQL JOIN to combine the price and coordinates data based on their shared postcodes. We added a column for geometry data and used the latitude and longitude data to create points. We then calculated the average value for each of the duplicate polygons."),(0,i.kt)("p",null,"Finally, we used the powerful mapping software QGIS to export the table from the database and modified the layer properties for visual appeal. Through this process, we were able to effectively organize and analyze the real estate data, allowing us to extract valuable insights and gain a deeper understanding of the market."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(9903).Z,width:"1534",height:"787"})),(0,i.kt)("p",null,"During our analysis of real estate data, we encountered an issue with some of the postal codes not being properly associated with the intended polygons. This issue had the potential to significantly impact the accuracy and usefulness of our data."),(0,i.kt)("p",null,"To address this issue and improve the accuracy of our data, we decided to use a different set of polygons (parishes) with a lower resolution for the next project. We hoped that this approach would help to more accurately associate the postal codes with the intended polygons, resulting in a more reliable dataset.---\nslug: infinite-universe\ntitle: Infinite Universe\nauthors: ecolazy"),(0,i.kt)("h2",{id:"tags-hello-docusaurus-7"},"tags: ","[hello, docusaurus]"),(0,i.kt)("h1",{id:"magical-sky"},"Magical Sky"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(5040).Z,width:"1472",height:"1937"})),(0,i.kt)("h1",{id:"infinite-universe"},"Infinite Universe"),(0,i.kt)("h2",{id:"method-of-creating-an-illusion-for-an-infinite-universe-utilizing-led-light-strips-acrylic-sheets-mirror-film-half-mirror-film-and-dichroic-film"},"Method of Creating an Illusion for an Infinite Universe Utilizing LED Light Strips, Acrylic Sheets, Mirror Film, Half Mirror Film, and Dichroic Film"),(0,i.kt)("h2",{id:"field-of-the-invention"},"Field of the Invention"),(0,i.kt)("p",null,"The present invention relates to the field of visual effects and illusion creation, specifically pertaining to a method that employs LED light strips, acrylic sheets, mirror film, half mirror film, and dichroic film to generate an immersive illusion of an infinite universe."),(0,i.kt)("h2",{id:"background-1"},"Background"),(0,i.kt)("p",null,"Visual effects and illusions have long fascinated individuals, resulting in the development of various techniques and devices to engage and captivate viewers. However, there exists a need for an innovative method that provides an enhanced and immersive experience of an infinite universe. The present invention addresses this need by combining specific components in a unique arrangement to achieve a visually stunning illusion."),(0,i.kt)("h2",{id:"objective"},"Objective"),(0,i.kt)("p",null,"The invention aims to provide a method for creating an illusion of an infinite universe. By meticulously arranging and utilizing LED light strips, acrylic sheets, mirror film, half mirror film, and dichroic film, the invention produces a captivating visual experience that simulates an expansive cosmic environment."),(0,i.kt)("h2",{id:"statements-of-invention"},"Statements of Invention"),(0,i.kt)("p",null,"The invention comprises the following components and their respective functions:\nLayer 1: Optical Acrylic with LED Light Strip This layer consists of an optical-grade acrylic sheet featuring an integrated LED light strip running along one edge. The acrylic sheet is designed to possess optimal light reflection and transmission properties. The LED light strip illuminates the acrylic sheet, generating a radiant and uniform distribution of light."),(0,i.kt)("p",null,"Layer 2: Mirror Film with Star-Shaped Holes The second layer incorporates a mirror film with strategically positioned star-shaped holes on the front face of the acrylic sheet. These apertures enable light to escape in a diffused manner, emulating the appearance of stars. The mirror film enhances the reflective properties, amplifying the impact of the illusion."),(0,i.kt)("p",null,"Layer 3: Dichroic Film The third layer involves the integration of a dichroic film renowned for its ability to selectively reflect and transmit specific wavelengths of light. This film introduces vibrant colors and dynamic effects to the illusion, causing the stars to exhibit various hues."),(0,i.kt)("p",null,"Layer 4: Acrylic Sheet with 20% Transmissivity Mirror Coating The fourth layer encompasses another acrylic sheet coated with a mirror coating, allowing approximately 20% of light transmission. This semi-transparent mirror coating permits the perception of both reflected and partially transmitted light, contributing to the depth and complexity of the illusion while immersing the viewer in an expansive visual landscape."),(0,i.kt)("h2",{id:"description-of-examples"},"Description of Examples"),(0,i.kt)("p",null,"The invention operates as follows: The LED light strip situated along the edge of the optical acrylic sheet provides uniform illumination across its surface. The light undergoes internal reflection within the acrylic sheet, aided by reflective white sheets covering its other faces. The star-shaped holes on the mirror film side of the acrylic sheet enable diffused light to escape, resulting in a celestial effect."),(0,i.kt)("p",null,"The escaping light passes through the dichroic film, which selectively reflects specific wavelengths of light, thereby causing the stars to appear in vibrant colors and adding depth to the illusion. The colored light is subsequently reflected onto the mirror coating of the entire assembly's front face. Due to the offset angle of the mirror coating, the reflected light creates the impression of an infinite universe extending beyond the boundaries of the assembly. This interplay of light, reflection, and color generates a captivating visual effect that enthralls the viewer and evokes a sense of expansiveness."),(0,i.kt)("h2",{id:"customization-and-application"},"Customization and Application"),(0,i.kt)("p",null,"The method for creating the illusion of an infinite universe using the described components can be further optimized and customized. The arrangement, size, and positioning of the components can be adjusted to achieve specific visual effects and desired levels of immersion. Additional layers or elements may also be incorporated to enhance the overall illusion.\nThe described method can be applied in various contexts, including but not limited to entertainment venues, art installations, virtual reality experiences, and other visual display systems. Its versatility allows for implementation in diverse settings to create captivating and immersive visual experiences."),(0,i.kt)("p",null,"In conclusion, the method for creating an illusion of an infinite universe using LED light strips, acrylic sheets, mirror film, half mirror film, and dichroic film offers a unique and visually captivating experience. The meticulous arrangement and interplay of these components result in a mesmerizing illusion that simulates the vastness and beauty of an infinite cosmic environment."),(0,i.kt)("p",null,"It is important to note that the aforementioned description serves as an illustration of preferred embodiments of the invention. Those skilled in the art will recognize various modifications and changes that can be made to the described method while remaining within the scope and spirit of the invention. Therefore, the scope of the invention should not be limited to the specific embodiments described, but should be determined by the appended claims and their legal equivalents."),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-1"},"sidebar_position: 1"),(0,i.kt)("h1",{id:"introduction"},"Introduction"),(0,i.kt)("p",null,"Welcome to the documentation of my previous work! This section is designed to provide detailed documentation of the projects and processes I have completed in the past."),(0,i.kt)("p",null,"The purpose of this documentation is multifaceted. Firstly, it serves as a reference for me to refer back to in the event that I need to repeat any of the steps or techniques used in my previous work. This is especially useful when the work was completed some time ago and I may not remember all of the details."),(0,i.kt)("p",null,"In addition to serving as a reference for myself, this documentation can also be used as a resource for others who may be interested in understanding my work or in replicating any of the techniques I have used. By providing detailed documentation, I aim to make my work more transparent and accessible to others."),(0,i.kt)("p",null,"Overall, this section is an important part of my professional practice as it helps me to document and preserve the knowledge and experience I have gained through my work. By keeping a record of my past projects and processes, I can continue to build upon my expertise and contribute to the field in a meaningful way.---"),(0,i.kt)("h2",{id:"sidebar_position-4"},"sidebar_position: 4"),(0,i.kt)("h1",{id:"provisioning-fedora-workstation"},"Provisioning Fedora Workstation"),(0,i.kt)("p",null,"This script installs and updates various packages and tools on a Fedora system. It installs the PostgreSQL database management system, the RPM Fusion repositories, and the Flathub repository. It also updates the system's packages and firmware, installs the Gnome Tweak Tool, some tools for working with CoreOS, and sets some configuration options for dnf (the Fedora package manager)."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'#!/bin/bash\n\n# Set Fedora version\nFEDORA_VER=$(rpm -E %fedora)\n\n# Remove any old pgadmin repos\nsudo rpm -e pgadmin4-fedora-repo\n\n# Set URLs for RPM Fusion repositories\nFREE_REPO_URL="https://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-${FEDORA_VER}.noarch.rpm"\nNONFREE_REPO_URL="https://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-${FEDORA_VER}.noarch.rpm"\n\n# Set URL for pgAdmin4 repository\nPGADMIN_REPO_URL="https://ftp.postgresql.org/pub/pgadmin/pgadmin4/yum/pgadmin4-fedora-repo-2-1.noarch.rpm"\n\n# Set dnf configuration options\necho \'max_parallel_downloads=10\' | sudo tee -a /etc/dnf/dnf.conf\necho \'fastestmirror=True\' | sudo tee -a /etc/dnf/dnf.conf\n\n# Add the PostgreSQL repository\nsudo rpm -i "$PGADMIN_REPO_URL"\n\n# Install RPM Fusion repositories\nsudo dnf install "$FREE_REPO_URL" "$NONFREE_REPO_URL"\n\n# Add Flathub repository\nflatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo\n\n# Update and upgrade packages\nsudo dnf update && sudo dnf upgrade\n\n# Refresh package list and update core packages\nsudo dnf upgrade --refresh\nsudo dnf groupupdate core\n\n# Update firmware\nsudo fwupdmgr refresh --force\nsudo fwupdmgr get-updates\nsudo fwupdmgr update\n\n# Install Gnome Tweak Tool and tool for working with CoreOS\nsudo dnf install gnome-tweak-tool rpi-imager coreos-installer\n\n# Install Qgis\nsudo dnf install qgis python3-qgis qgis-grass qgis-server\n\n# Install pgadmin4\nsudo tum install pgadmin4\n\n# Install ranger\nsudo dnf ranger\n\n# Install zsh\nsudo dnf zsh\n\n# Install kitty\nsudo dnf kitty\n\n# Install psql\nsudo dnf psql\n\n# Oh My ZSH\nwget https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh\nsh install.sh\n')),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-5"},"sidebar_position: 5"),(0,i.kt)("h1",{id:"configuring-visual-studio-code"},"Configuring Visual Studio Code"),(0,i.kt)("h3",{id:"generate-list-of-extensions-from-existing-installation"},"Generate list of extensions from existing installation"),(0,i.kt)("p",null,"When this command is run, it will generate a list of all the installed Visual Studio Code extensions and save it to the extensions.md file. The extension names will be listed one per line in the file."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"code --list-extensions > extensions.md\n")),(0,i.kt)("p",null,"Here's the resulting file"),(0,i.kt)("h3",{id:"extensionsmd"},"extensions.md"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-md"},"aaron-bond.better-comments\nbierner.markdown-preview-github-styles\ndonjayamanne.githistory\neamodio.gitlens\nesbenp.prettier-vscode\nformulahendry.auto-rename-tag\nIvanGrigorov.openaicodehelper\njamiewoodio.cisco\nTabNine.tabnine-vscode\nvoldemortensen.rainbow-tags\nyzhang.markdown-all-in-one\n")),(0,i.kt)("h3",{id:"install-extensions-from-md-file"},"Install extensions from md file"),(0,i.kt)("p",null,"The xargs command is used to build and execute a command from standard input. It takes the input, splits it into separate arguments (using the -n1 option, which means to take one argument at a time), and then runs the specified command (in this case, code --install-extension) on each argument."),(0,i.kt)("p",null,"The < extensions.md part of the command passes the contents of the extensions.md file as standard input to the xargs command."),(0,i.kt)("p",null,"So, in this case, the command reads the extensions.md file, which should contain a list of extension names (one per line), and it installs each extension using the code command."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"xargs -n1 code --install-extension < extensions.md\n")),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-3"},"sidebar_position: 3"),(0,i.kt)("h1",{id:"rename-all-linux-frendly"},"Rename all linux frendly"),(0,i.kt)("p",null,"This command will rename all the files in the current directory, replacing any non-alphanumeric or non-period characters with nothing."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'for file in *; do mv "$file" "$(echo ${file//[^a-zA-Z0-9.]/})" ; done\n')),(0,i.kt)("h2",{id:"references-1"},"References"),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-2"},"sidebar_position: 2"),(0,i.kt)("h1",{id:"extract-all-zips"},"Extract all zips"),(0,i.kt)("p",null,"This script will find all .zip files in the current directory and its subdirectories, and it will unzip each of them."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'#!/usr/bin/bash\nfind . -name "*.zip" -exec unzip {} \\;\n')),(0,i.kt)("h2",{id:"references-2"},"References"),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-1-1"},"sidebar_position: 1"),(0,i.kt)("h1",{id:"copy-files-into-directories-by-extension"},"Copy files into directories by extension"),(0,i.kt)("p",null,"This script searches all subdirectories for files and moves them into subdirectories named after their file extensions, while also handling filenames that contain special characters:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'find . -type f | while read -r filename; do\n  base=$(basename "$filename" .*)\n  ext=${filename##*.}\n  counter=1\n  sanitized_base=$(echo "$base" | tr -dc \'[:alnum:]\\n\\r\')\n  sanitized_ext=$(echo "$ext" | tr -dc \'[:alnum:]\\n\\r\')\n  while [[ -f "${sanitized_ext}/${sanitized_base}_${counter}.${sanitized_ext}" ]]; do\n      ((counter++))\n  done\n  mkdir -p "${sanitized_ext}"\n  mv "$filename" "${sanitized_ext}/${sanitized_base}_${counter}.${sanitized_ext}"\ndone\n\n\n## now test there is files in the directories  \n\n\n\n\n')),(0,i.kt)("p",null,'If a file with the same name already exists in the destination directory, it will append a number to the file name to make it unique. For example, if the file "example.txt" already exists in the "txt" directory, the script will move the new file "example.txt" to "txt/example_1.txt". If there is already a file "example_1.txt" in the "txt" directory, the script will move the new file to "txt/example_2.txt", and so on.'),(0,i.kt)("p",null,"The script also sanitizes the file names to remove any special characters that might cause errors. It does this by using the tr command to remove all characters that are not alphanumeric or newline characters from the file names. This ensures that the resulting file names will only contain safe characters."),(0,i.kt)("h2",{id:"references---"},"References---"),(0,i.kt)("h2",{id:"sidebar_position-4-1"},"sidebar_position: 4"),(0,i.kt)("h1",{id:"setup-rclone"},"Setup rclone"),(0,i.kt)("h3",{id:"install-rclone-from-the-package-manager"},"Install rclone from the package manager"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sudo dnf install rclone\n")),(0,i.kt)("h3",{id:"run-the-rclone-configuration-wizard-to-set-up-a-remote-storage-provider"},"Run the rclone configuration wizard to set up a remote storage provider"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"rclone config\n")),(0,i.kt)("h3",{id:"open-the-rclone-service-file-in-a-text-editor"},"Open the rclone service file in a text editor"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sudo vim ~/.config/systemd/user/rclone.service\n")),(0,i.kt)("h3",{id:"add-the-following-content-to-the-service-file"},"Add the following content to the service file"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"[Unit]\nDescription=Rclone Sync\nAfter=network.target\n\n[Service]\nType=simple\n# Specify the sync command to be run at boot\nExecStart=/usr/bin/rclone sync /Documents/ google:Documents/ \n# Restart the service if it fails\nRestart=on-failure\n\n[Install]\n# Enable the service to start at boot\nWantedBy=multi-user.target\n")),(0,i.kt)("h3",{id:"check-the-status-of-the-rclone-service"},"Check the status of the rclone service"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl --user status rclone.service\n")),(0,i.kt)("h3",{id:"start-the-rclone-service-immediately"},"Start the rclone service immediately"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl --user start rclone.service\n")),(0,i.kt)("h3",{id:"enable-the-rclone-service-to-start-at-boot"},"Enable the rclone service to start at boot"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl --user enable rclone.service\n")),(0,i.kt)("h3",{id:"reload-the-system-manager-configuration"},"Reload the system manager configuration"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl --user daemon-reload\n```---\nsidebar_position: 5\n---\n\n# Setting up Qgis\n\n``` bash\nsudo dnf install qgis python3-qgis qgis-grass qgis-server\n")),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-2-1"},"sidebar_position: 2"),(0,i.kt)("h1",{id:"infrastructure-as-a-service"},"Infrastructure as a Service"),(0,i.kt)("p",null,'IaaS stands for "Infrastructure as a Service." It refers to a cloud computing model in which an organization outsources the infrastructure necessary to support the operation of its applications and services. This includes physical infrastructure, such as servers, storage, and networking, as well as virtual infrastructure, such as operating systems, middleware, and runtime environments. With IaaS, the organization pays for the infrastructure resources it consumes on a pay-as-you-go basis.---'),(0,i.kt)("h2",{id:"sidebar_position-3-1"},"sidebar_position: 3"),(0,i.kt)("h1",{id:"platform-as-a-service"},"Platform as a Service"),(0,i.kt)("p",null,'PaaS stands for "Platform as a Service." It refers to a cloud computing model in which an organization develops and deploys applications on a cloud-based platform provided by a third-party provider. The provider manages the infrastructure and middleware required to support the applications, allowing the organization to focus on developing and deploying the applications. The organization pays for the platform on a pay-as-you-go basis, typically based on the resources consumed by the applications.---'),(0,i.kt)("h2",{id:"sidebar_position-1-2"},"sidebar_position: 1"),(0,i.kt)("h1",{id:"software-as-a-service"},"Software as a Service"),(0,i.kt)("p",null,'SaaS stands for "Software as a Service." It refers to a cloud computing model in which an organization uses software applications that are hosted and managed by a third-party provider. The organization pays for the software on a subscription basis, typically based on the number of users or the amount of data processed. With SaaS, the organization does not need to worry about installing, configuring, or maintaining the software, as these tasks are handled by the provider.---'),(0,i.kt)("h2",{id:"sidebar_position-2-2"},"sidebar_position: 2"),(0,i.kt)("h1",{id:"setting-up-influxdb-database-server-with-podman"},"Setting up InfluxDB Database Server with Podman"),(0,i.kt)("p",null,"First create a pod and inflluxdb container using podman, then generate a YAML file using podman play."),(0,i.kt)("p",null,"The YAML file can be used to recreate the pod in podman, or in kubernetes."),(0,i.kt)("h3",{id:"create-a-pod"},"Create a pod"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman pod create -p 8086:8086 -p 1883:1883 -p 9001:9001 -n monitoring\n")),(0,i.kt)("h3",{id:"pull-influxdb-image"},"Pull influxdb image"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman pull docker.io/influxdb:latest\n")),(0,i.kt)("h3",{id:"run-image-in-pod"},"Run image in pod"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman run -d -t \\\n--name influxdb \\\n--pod monitoring \\\ninfluxdb:latest\n")),(0,i.kt)("h3",{id:"pull-mosquitto-image"},"Pull mosquitto image"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman pull docker.io/eclipse-mosquitto\n")),(0,i.kt)("h3",{id:"run-image-in-pod-1"},"Run image in pod"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman run -t \\\n--name mosquitto \\\n--pod monitoring \\\neclipse-mosquitto\n")),(0,i.kt)("h3",{id:"generate-yaml-file"},"Generate YAML file"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman generate kube monitoring -f monitoring-stack.yaml\n")),(0,i.kt)("h2",{id:"heres-the-yaml-file"},"Here's the YAML file"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},'# Save the output of this file and use kubectl create -f to import\n# it into Kubernetes.\n#\n# Created with podman-4.3.1\napiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    io.kubernetes.cri-o.ContainerType/influxdb: container\n    io.kubernetes.cri-o.ContainerType/mosquitto: container\n    io.kubernetes.cri-o.SandboxID/influxdb: 3e6d0de4f62b7090a2b3e0e4d64f69881894d6d4988b4f87cde736c43e26a62\n    io.kubernetes.cri-o.SandboxID/mosquitto: 3e6d0de4f62b7090a2b3e0e4d64f69881894d6d4988b4f87cde736c43e26a62\n    io.kubernetes.cri-o.TTY/influxdb: "true"\n    io.kubernetes.cri-o.TTY/mosquitto: "true"\n    io.podman.annotations.autoremove/influxdb: "FALSE"\n    io.podman.annotations.autoremove/mosquitto: "FALSE"\n    io.podman.annotations.init/influxdb: "FALSE"\n    io.podman.annotations.init/mosquitto: "FALSE"\n    io.podman.annotations.privileged/influxdb: "FALSE"\n    io.podman.annotations.privileged/mosquitto: "FALSE"\n    io.podman.annotations.publish-all/influxdb: "FALSE"\n    io.podman.annotations.publish-all/mosquitto: "FALSE"\n  creationTimestamp: "2022-12-31T02:23:51Z"\n  labels:\n    app: monitoring\n  name: monitoring\nspec:\n  automountServiceAccountToken: false\n  containers:\n  - args:\n    - influxd\n    image: docker.io/library/influxdb:latest\n    name: influxdb\n    ports:\n    - containerPort: 1883\n      hostPort: 1883\n    - containerPort: 8086\n      hostPort: 8086\n    - containerPort: 9001\n      hostPort: 9001\n    resources: {}\n    securityContext:\n      capabilities:\n        drop:\n        - CAP_MKNOD\n        - CAP_NET_RAW\n        - CAP_AUDIT_WRITE\n    tty: true\n    volumeMounts:\n    - mountPath: /etc/influxdb2\n      name: 130b34101cdf2ca9f58b6166ea376a0f79c5fe18889a00c42f458d3259a8fd8e-pvc\n    - mountPath: /var/lib/influxdb2\n      name: 70d043a228ff0ccb924b9950887e9b947cfebed5956652cbf2d454ac26a66879-pvc\n  - args:\n    - /usr/sbin/mosquitto\n    - -c\n    - /mosquitto/config/mosquitto.conf\n    image: docker.io/library/eclipse-mosquitto:latest\n    name: mosquitto\n    resources: {}\n    securityContext:\n      capabilities:\n        drop:\n        - CAP_MKNOD\n        - CAP_NET_RAW\n        - CAP_AUDIT_WRITE\n    tty: true\n    volumeMounts:\n    - mountPath: /mosquitto/log\n      name: f01fc59a9790fea52fd1e862b517d10aaefa3af04ad70e912004b72fd64e95b0-pvc\n    - mountPath: /mosquitto/data\n      name: 3439da031be88b060d2c4fb4c835a309c573809fcfb45f98dfc12e281f6d263e-pvc\n  enableServiceLinks: false\n  hostname: monitoring\n  restartPolicy: Never\n  volumes:\n  - name: 130b34101cdf2ca9f58b6166ea376a0f79c5fe18889a00c42f458d3259a8fd8e-pvc\n    persistentVolumeClaim:\n      claimName: 130b34101cdf2ca9f58b6166ea376a0f79c5fe18889a00c42f458d3259a8fd8e\n  - name: 70d043a228ff0ccb924b9950887e9b947cfebed5956652cbf2d454ac26a66879-pvc\n    persistentVolumeClaim:\n      claimName: 70d043a228ff0ccb924b9950887e9b947cfebed5956652cbf2d454ac26a66879\n  - name: f01fc59a9790fea52fd1e862b517d10aaefa3af04ad70e912004b72fd64e95b0-pvc\n    persistentVolumeClaim:\n      claimName: f01fc59a9790fea52fd1e862b517d10aaefa3af04ad70e912004b72fd64e95b0\n  - name: 3439da031be88b060d2c4fb4c835a309c573809fcfb45f98dfc12e281f6d263e-pvc\n    persistentVolumeClaim:\n      claimName: 3439da031be88b060d2c4fb4c835a309c573809fcfb45f98dfc12e281f6d263e\nstatus: {}\n')),(0,i.kt)("h3",{id:"test-yaml-file"},"Test YAML file"),(0,i.kt)("p",null,"Delete containers"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman rm -vf influxdb\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman rm -vf mosquitto\n")),(0,i.kt)("p",null,"Delete pod"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman pod rm monitoring\n")),(0,i.kt)("p",null,"Re-build pod using podman play and YAML file."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman play kube monitoring-stack.yaml\n")),(0,i.kt)("h3",{id:"reference"},"Reference"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://oracle-base.com/articles/linux/podman-generate-and-play-kubernetes-yaml-files#:~:text=Podman%20can%20generate%20Kubernetes%20YAML,similar%20to%20Docker%20Compose%20files."},"Oracle-Base")),(0,i.kt)("h3",{id:"to-do"},"To do"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"mosquitto configuration"),(0,i.kt)("li",{parentName:"ul"},"influxdb directory---\nsidebar_position: 1")),(0,i.kt)("hr",null),(0,i.kt)("h1",{id:"provisioning-fedora-coreos-on-the-raspberry-pi-4"},"Provisioning Fedora CoreOS on the Raspberry Pi 4"),(0,i.kt)("h3",{id:"prep-seperate-usb-for-firmware"},"prep seperate usb for firmware"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"VERSION=v1.32  # use latest one from https://github.com/pftf/RPi4/releases\nUEFIDISK=/dev/sdX\nsudo mkfs.vfat $UEFIDISK\nmkdir /tmp/UEFIdisk\nsudo mount $UEFIDISK /tmp/UEFIdisk\npushd /tmp/UEFIdisk\nsudo curl -LO https://github.com/pftf/RPi4/releases/download/${VERSION}/RPi4_UEFI_Firmware_${VERSION}.zip\nsudo unzip RPi4_UEFI_Firmware_${VERSION}.zip\nsudo rm RPi4_UEFI_Firmware_${VERSION}.zip\npopd\nsudo umount /tmp/UEFIdisk\n")),(0,i.kt)("h3",{id:"install-coreos-tools"},"Install CoreOS tools"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sudo dnf install -y rpi-imager coreos-installer butane ignition-validate\n")),(0,i.kt)("h3",{id:"make-working-directory-and-change-to-it"},"Make working directory and change to it"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir ~/coreos\ncd ~/coreos\n")),(0,i.kt)("h3",{id:"download-coreos-image"},"Download CoreOS image"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"coreos-installer download -p qemu -f qcow2.xz --decompress\n")),(0,i.kt)("h3",{id:"rename-image-to-simpler-name"},"Rename image to simpler name"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"mv *.qcow2 fedora-coreos.qcow2\n")),(0,i.kt)("h3",{id:"create-rpictbu"},"Create rpict.bu"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},'variant: fcos\nversion: 1.4.0\npasswd:\n  users:\n    - name: core\n      ssh_authorized_keys:\n        - ssh-rsa AAAA...\nsystemd:\n  units:\n    - name: serial-getty@ttyS0.service\n      dropins:\n      - name: autologin-core.conf\n        contents: |\n          [Service]\n          # Override Execstart in main unit\n          ExecStart=\n          # Add new Execstart with `-` prefix to ignore failure\n          ExecStart=-/usr/sbin/agetty --autologin core --noclear %I $TERM\n          TTYVTDisallocate=no\n    - name: failure.service\n      enabled: true\n      contents: |\n        [Service]\n        Type=oneshot\n        ExecStart=/usr/bin/false\n        RemainAfterExit=yes\n\n        [Install]\n        WantedBy=multi-user.target\n    - name: etcd-member.service\n      enabled: true\n      contents: |\n        [Unit]\n        Description=Run a single node etcd\n        After=network-online.target\n        Wants=network-online.target\n\n        [Service]\n        ExecStartPre=mkdir -p /var/lib/rpict2mqtt\n        ExecStartPre=-/bin/podman kill rpict2mqtt\n        ExecStartPre=-/bin/podman rm rpict2mqtt\n        ExecStartPre=-/bin/podman pull docker.io/gtricot/rpict-mqtt:latest\n        ExecStart=/bin/podman run --name rpict2mqtt \\\n                           --device=/dev/ttyAMA0:/dev/ttyAMA0 \\\n                            -e MQTT_URL="mqtt://my_mqtt_broker:1883" \\\n                           -e MQTT_USER="my-super-user" \\\n                           -e MQTT_PASSWORD="my-secret-password" \\\n                           -e MQTT_BASE_TOPIC="custom-rpict-topic" \\\n                           -e ABSOLUTE_VALUES=true \\\n                           -e SENSOR_VALUE_THRESHOLD=2 \\\n                            gtricot/rpict-mqtt\n        ExecStop=/bin/podman stop rpict2mqtt\n\n        [Install]\n        WantedBy=multi-user.target\nstorage:\n  files:\n    - path: /etc/hostname\n      mode: 0644\n      contents:\n        inline: |\n          tutorial\n    - path: /etc/profile.d/systemd-pager.sh\n      mode: 0644\n      contents:\n        inline: |\n          # Tell systemd to not use a pager when printing information\n          export SYSTEMD_PAGER=cat\n')),(0,i.kt)("h3",{id:"transpile-butane-file-into-an-ignition-file"},"Transpile butane file into an ignition file"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"butane --pretty --strict rpict.bu --output rpict.ign\n")),(0,i.kt)("h2",{id:"test-ignition-file-in-virtual-machine"},"Test ignition file in virtual machine"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"ignition-validate rpict.ign && echo 'Success!'\n")),(0,i.kt)("h4",{id:"setup-the-correct-selinux-label-to-allow-access-to-the-config"},"Setup the correct SELinux label to allow access to the config"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"chcon --verbose --type svirt_home_t rpict.ign\n")),(0,i.kt)("h4",{id:"start-a-fedora-coreos-virtual-machine"},"Start a Fedora CoreOS virtual machine"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'virt-install --name=fcos --vcpus=2 --ram=2048 --os-variant=fedora-coreos-stable \\\n    --import --network=bridge=virbr0 --graphics=none \\\n    --qemu-commandline="-fw_cfg name=opt/com.coreos/config,file=${PWD}/rpict.ign" \\\n    --disk=size=20,backing_store=${PWD}/fedora-coreos.qcow2\n')),(0,i.kt)("h4",{id:"exit-and-destroy-virtual-machine"},"Exit and destroy virtual machine"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"CTRL + ] to exit kvm"),(0,i.kt)("h3",{parentName:"blockquote",id:"to-destroy-run"},"to destroy run"),(0,i.kt)("pre",{parentName:"blockquote"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"virsh destroy fcos\nvirsh undefine --remove-all-storage fcos\n"))),(0,i.kt)("h3",{id:"write-to-disk"},"Write to disk"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"## set disc\nFCOSDISK=/dev/sdX\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"# Create customized.iso which:\ncoreos-installer iso customize \\\n    --architecture=aarch64 \\\n    --dest-device $FCOSDISK \\ # - Automatically installs to /dev/sda\n    --dest-ignition config.ign \\ # - Provisions with config.ign\n    --network-keyfile $networkManagerConnectionFile  \\ # -  network configuration\n    --ignition-ca ca.pem \\ # - Trusts HTTPS certificates signed by ca.pem\n    --post-install post.sh \\ # - Runs post.sh after installing\n    -o custom.iso input.iso\n")),(0,i.kt)("h2",{id:"reference-1"},"Reference"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://docs.fedoraproject.org/en-US/fedora-coreos/provisioning-raspberry-pi4/"},"FedoraOnRpi")),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://coreos.github.io/coreos-installer/customizing-install/#customize-options"},"customizing-install")),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://github.com/pftf/RPi4"},"pftf")),(0,i.kt)("h3",{id:"to-do-1"},"To do"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"setup MQTT gateway"),(0,i.kt)("li",{parentName:"ul"},"write CoreOS to SD and boot pi with external monitor"),(0,i.kt)("li",{parentName:"ul"},"test whether /dev/ttyAMA0 is accesible with CoreOS on RPI4---\nsidebar_position: 3")),(0,i.kt)("hr",null),(0,i.kt)("h1",{id:"carbon-dioxide"},"Carbon Dioxide"),(0,i.kt)("h3",{id:"hardware"},"Hardware"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"MH-Z19B NDIR infrared gas module is a common type, small size sensor, using non-dispersive infrared (NDIR) principle to detect the existence of CO 2 in the air, with good selectivity, non-oxygen dependent and long life. Built-in temperature compensation; and it has UART output and PWM output. It is developed by the tight integration of mature infrared absorbing gas detection technology, precision optical circuit design and superior circuit design.")),(0,i.kt)("p",null,"General"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"MH-Z19B Carbon Dioxide Gas Sensor"),(0,i.kt)("li",{parentName:"ul"},"uses the principle of non-scattered infrared"),(0,i.kt)("li",{parentName:"ul"},"simultaneous serial, analog and PWM output ")),(0,i.kt)("h3",{id:"script"},"Script"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"#!/usr/bin/python3\n\nimport socket\nimport ssl\nimport sys\nimport re\nimport json\nimport os.path\nimport argparse\nfrom time import time, sleep, localtime, strftime\nfrom colorama import init as colorama_init\nfrom colorama import Fore, Back, Style\nfrom configparser import ConfigParser\nfrom unidecode import unidecode\nimport mh_z19\nimport paho.mqtt.client as mqtt\nimport sdnotify\n\nproject_name = 'MH-Z19 Raspberry MQTT Client/Daemon'\nproject_url = 'https://github.com/R4scal/mhz19-mqtt-daemon'\n\nif False:\n    # will be caught by python 2.7 to be illegal syntax\n    print('Sorry, this script requires a python3 runtime environemt.', file=sys.stderr)\n\n\n# Argparse\nparser = argparse.ArgumentParser(description=project_name, epilog='For further details see: ' + project_url)\nparser.add_argument('--config_dir', help='set directory where config.ini is located', default=sys.path[0])\nparse_args = parser.parse_args()\n\n# Intro\ncolorama_init()\nprint(Fore.GREEN + Style.BRIGHT)\nprint(project_name)\nprint('Source:', project_url)\nprint(Style.RESET_ALL)\n\n# Systemd Service Notifications - https://github.com/bb4242/sdnotify\nsd_notifier = sdnotify.SystemdNotifier()\n\n# Logging function\ndef print_line(text, error = False, warning=False, sd_notify=False, console=True):\n    timestamp = strftime('%Y-%m-%d %H:%M:%S', localtime())\n    if console:\n        if error:\n            print(Fore.RED + Style.BRIGHT + '[{}] '.format(timestamp) + Style.RESET_ALL + '{}'.format(text) + Style.RESET_ALL, file=sys.stderr)\n        elif warning:\n            print(Fore.YELLOW + '[{}] '.format(timestamp) + Style.RESET_ALL + '{}'.format(text) + Style.RESET_ALL)\n        else:\n            print(Fore.GREEN + '[{}] '.format(timestamp) + Style.RESET_ALL + '{}'.format(text) + Style.RESET_ALL)\n    timestamp_sd = strftime('%b %d %H:%M:%S', localtime())\n    if sd_notify:\n        sd_notifier.notify('STATUS={} - {}.'.format(timestamp_sd, unidecode(text)))\n\n# Eclipse Paho callbacks - http://www.eclipse.org/paho/clients/python/docs/#callbacks\ndef on_connect(client, userdata, flags, rc):\n    if rc == 0:\n        print_line('MQTT connection established', console=True, sd_notify=True)\n        print()\n    else:\n        print_line('Connection error with result code {} - {}'.format(str(rc), mqtt.connack_string(rc)), error=True)\n        #kill main thread\n        os._exit(1)\n\ndef on_publish(client, userdata, mid):\n    #print_line('Data successfully published.')\n    pass\n\n\n# Load configuration file\nconfig_dir = parse_args.config_dir\n\nconfig = ConfigParser(delimiters=('=', ))\nconfig.optionxform = str\nconfig.read([os.path.join(config_dir, 'config.ini.dist'), os.path.join(config_dir, 'config.ini')])\n\nreporting_mode = config['General'].get('reporting_method', 'homeassistant-mqtt')\ndaemon_enabled = config['Daemon'].getboolean('enabled', True)\nsleep_period = config['Daemon'].getint('period', 300)\ndetection_range = config['MH-Z19'].getint('detection_range', 5000)\n\nif reporting_mode == 'homeassistant-mqtt':\n    default_base_topic = 'homeassistant'\n\nbase_topic = config['MQTT'].get('base_topic', default_base_topic).lower()\n\n# Check configuration\nif reporting_mode not in ['homeassistant-mqtt']:\n    print_line('Configuration parameter reporting_mode set to an invalid value', error=True, sd_notify=True)\n    sys.exit(1)\n\nprint_line('Configuration accepted', console=False, sd_notify=True)\n\n# MQTT connection\nif reporting_mode in ['homeassistant-mqtt']:\n    print_line('Connecting to MQTT broker ...')\n    mqtt_client = mqtt.Client()\n    mqtt_client.on_connect = on_connect\n    mqtt_client.on_publish = on_publish\n\n    if config['MQTT'].getboolean('tls', False):\n        mqtt_client.tls_set(\n            ca_certs=config['MQTT'].get('tls_ca_cert', None),\n            keyfile=config['MQTT'].get('tls_keyfile', None),\n            certfile=config['MQTT'].get('tls_certfile', None),\n            # Auto-negotiate the highest protocol version that both the client and server support, and configure the\n            # context client-side connections. Other protocol options are deprecated\n            tls_version=ssl.PROTOCOL_TLS_CLIENT\n        )\n\n    if config['MQTT'].get('username'):\n        mqtt_client.username_pw_set(config['MQTT'].get('username'), config['MQTT'].get('password', None))\n    try:\n        mqtt_client.connect(config['MQTT'].get('hostname', 'localhost'),\n                            port=config['MQTT'].getint('port', 1883),\n                            keepalive=config['MQTT'].getint('keepalive', 60))\n    except:\n        print_line('MQTT connection error. Please check your settings in the configuration file \"config.ini\"', error=True, sd_notify=True)\n        sys.exit(1)\n    else:\n       mqtt_client.loop_start()\n       sleep(1.0) # some slack to establish the connection\n\nsd_notifier.notify('READY=1')\n\n# Initialize DHT sensor\nsensor_name = '{}_mhz19'.format(socket.gethostname()).replace(\"-\", \"_\")\nprint_line('Current sensor name is \"{}\"'.format(sensor_name).lower())\n\n# Discovery Announcement\nif reporting_mode == 'homeassistant-mqtt':\n    print_line('Announcing MH-Z19 to MQTT broker for auto-discovery ...')\n    topic_path = '{}/sensor/{}'.format(base_topic, sensor_name)\n    base_payload = {\n        \"state_topic\": \"{}/state\".format(topic_path).lower()\n    }\n    # Temperature\n    payload = dict(base_payload.items())\n    payload['unit_of_measurement'] = '\xb0C'\n    payload['value_template'] = \"{{ value_json.temperature }}\"\n    payload['name'] = \"{} Temperature\".format(sensor_name)\n    payload['device_class'] = 'temperature'\n    mqtt_client.publish('{}/{}_temperature/config'.format(topic_path, sensor_name).lower(), json.dumps(payload), 1, True)\n    # CO2\n    payload = dict(base_payload.items())\n    payload['unit_of_measurement'] = 'ppm'\n    payload['value_template'] = \"{{ value_json.co2 }}\"\n    payload['name'] = \"{} CO2\".format(sensor_name)\n    mqtt_client.publish('{}/{}_co2/config'.format(topic_path, sensor_name).lower(), json.dumps(payload), 1, True)\n    # SS\n    payload = dict(base_payload.items())\n    payload['unit_of_measurement'] = ''\n    payload['value_template'] = \"{{ value_json.SS }}\"\n    payload['name'] = \"{} SS\".format(sensor_name)\n    mqtt_client.publish('{}/{}_ss/config'.format(topic_path, sensor_name).lower(), json.dumps(payload), 1, True)\n    # UhUl\n    payload = dict(base_payload.items())\n    payload['unit_of_measurement'] = ''\n    payload['value_template'] = \"{{ value_json.UhUl }}\"\n    payload['name'] = \"{} UhUl\".format(sensor_name)\n    mqtt_client.publish('{}/{}_uhul/config'.format(topic_path, sensor_name).lower(), json.dumps(payload), 1, True)\n\n\nif detection_range == 5000:\n    mh_z19.detection_range_5000(serial_console_untouched=True)\nelif detection_range == 10000:\n    mh_z19.detection_range_10000(serial_console_untouched=True)\nelif detection_range == 2000:\n    mh_z19.detection_range_2000(serial_console_untouched=True)\nelse:\n    # Unknown detection range, setting to 5000\n    mh_z19.detection_range_5000(serial_console_untouched=True)\n\n# Sensor data retrieval and publication\nwhile True:\n   print_line('Retrieving data from MH-Z19 sensor...')\n   data = mh_z19.read_all(serial_console_untouched=True)\n   if len(data) == 0:\n      print_line('Unable to get data form sensor.', error=True, sd_notify=True)\n      print()\n      continue\n   else:\n     print_line('Result: {}'.format(json.dumps(data)))\n     if reporting_mode == 'homeassistant-mqtt':\n          print_line('Publishing to MQTT topic \"{}/sensor/{}/state\"'.format(base_topic, sensor_name).lower())\n          mqtt_client.publish('{}/sensor/{}/state'.format(base_topic, sensor_name).lower(), json.dumps(data))\n          sleep(0.5) # some slack for the publish roundtrip and callback function\n     else:\n          raise NameError('Unexpected reporting_mode.')\n     print()\n\n     print_line('Status messages published', console=False, sd_notify=True)\n\n   if daemon_enabled:\n      print_line('Sleeping ({} seconds) ...'.format(sleep_period))\n      sleep(sleep_period)\n      print()\n   else:\n      print_line('Execution finished in non-daemon-mode', sd_notify=True)\n      break\n")),(0,i.kt)("h2",{id:"references-3"},"References"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Infrared_spectroscopy"},"Wikipedia"),"\n",(0,i.kt)("a",{parentName:"p",href:"https://www.winsen-sensor.com/sensors/co2-sensor/mh-z19b.html"},"Winsen-Sensors"),"\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/R4scal/mhz19-mqtt-daemon"},"Code"),"---"),(0,i.kt)("h2",{id:"sidebar_position-1-3"},"sidebar_position: 1"),(0,i.kt)("h1",{id:"starting-scripts-with-systemd"},"Starting Scripts with Systemd"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"cp script.py /usr/local/bin/script.py\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-service"},"[Unit]\nBefore=systemd-user-sessions.service\nWants=network-online.target\nAfter=network-online.target\nConditionPathExists=!/var/lib/issuegen-public-ipv4\n\n[Service]\nType=oneshot\nExecStart=/usr/local/bin/public-ipv4.sh\nExecStartPost=/usr/bin/touch /var/lib/issuegen-public-ipv4\nRemainAfterExit=yes\n\n[Install]\nWantedBy=multi-user.target\n\n")),(0,i.kt)("h2",{id:"references-4"},"References"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://docs.fedoraproject.org/en-US/fedora-coreos/tutorial-services/"},"RPICT7V1")),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-1-4"},"sidebar_position: 1"),(0,i.kt)("h1",{id:"ac-current"},"AC Current"),(0,i.kt)("h3",{id:"hardware-1"},"Hardware"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"RPICT7V1 AC current sensor "),(0,i.kt)("li",{parentName:"ul"},"SCT-013-000 100a Current Transformer"),(0,i.kt)("li",{parentName:"ul"},"UK: 77DB-06-09 Voltage Sensor")),(0,i.kt)("h3",{id:"script-1"},"Script"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'MQTT_SERV = "localhost"\nMQTT_PATH = "RPICT7V1"\nMQTT_USER = ""\nMQTT_PASS = ""\n\nCHANNELS = ["NodeID", "RP1", "RP2", "RP3", "RP4", "RP5", "RP6", "RP7",\n        "Irms1", "Irms2", "Irms3", "Irms4", "Irms5", "Irms6", "Irms7",\n        "Vrms"]\n\nimport paho.mqtt.client as mqtt\nimport serial\nser = serial.Serial(\'/dev/ttyAMA0\', 38400)\n\nclient = mqtt.Client("P1")\nclient.username_pw_set(MQTT_USER, MQTT_PASS)\nclient.connect(MQTT_SERV)\n\ntry:\n    while 1:\n        # Read one line from the serial buffer\n         line = ser.readline()\n     \n        # Remove the trailing carriage return line feed\n        line = line[:-2]\n     \n        # Create an array of the data\n        Z = line.split(\' \')\n     \n        # Print it for debug\n        print line\n     \n        # Publish to the MQTT broker\n        for i in range(len(Z)):\n            client.publish("%s/%s" % (MQTT_PATH, CHANNELS[i]), Z[i]) \n \nexcept KeyboardInterrupt:\n    client.disconnect()\n    ser.close()\n')),(0,i.kt)("h2",{id:"references-5"},"References"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"http://lechacal.com/wiki/index.php?title=Raspberrypi_Current_and_Temperature_Sensor_Adaptor#RPICT_Series"},"RPICT7V1"),"---"),(0,i.kt)("h2",{id:"sidebar_position-2-3"},"sidebar_position: 2"),(0,i.kt)("h1",{id:"car-obd-port"},"Car OBD Port"),(0,i.kt)("h3",{id:"hardware-2"},"Hardware"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"OBD-II PIDs (On-board diagnostics Parameter IDs) are codes used to request data from a vehicle, used as a diagnostic tool.")),(0,i.kt)("h3",{id:"script-2"},"Script"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'#!/usr/bin/python3\nimport obd\nimport time\nimport json\nimport paho.mqtt.client as mqtt\n\n# define variables\nconnection = obd.Async("/dev/ttyUSB0")\n\n# global variables to hold values\nlatest_speed = {}\nlatest_rpm = {}\nlatest_engine_load = {}\nlatest_coolant_temp = {}\nlatest_intake_pressure = {}\nlatest_intake_temp = {}\nlatest_maf = {}\nlatest_distance_w_mil = {}\nlatest_fuel_rail_pressure_direct = {}\nlatest_commanded_egr = {}\nlatest_fuel_level = {}\nlatest_barometric_pressure = {}\n\n# loop\ndef myLoop():\n    message = [\n                {\n                    "measurement": "obd",\n                        "fields": {\n                            "commanded_egr": latest_commanded_egr,\n                            "speed": latest_speed,\n                            "rpm": latest_rpm,\n                            "engine_load": latest_engine_load,\n                            "coolant_temp": latest_coolant_temp,\n                            "intake_pressure": latest_intake_pressure,\n                            "intake_temp": latest_intake_temp,                            \n                            "maf": latest_maf,\n                            "distance_w_mil": latest_distance_w_mil,\n                            "fuel_rail_pressure_direct": latest_fuel_rail_pressure_direct,\n                            "commanded_egr": latest_commanded_egr,\n                            "fuel_level": latest_fuel_level,\n                            "barometric_pressure": latest_barometric_pressure\n                    }\n            }\n            ]\n    # convert to json string\n    data_out=json.dumps(message) \n\n    # This is the Publisher  \n    client = mqtt.Client()\n    client.username_pw_set(username="admin",password="35d8e")\n    client.connect("localhost",1883,60)\n    client.publish("sensors/obd", data_out);\n    client.disconnect();\n    time.sleep(3)\n\n# callbacks for each sensor\ndef new_speed(r):\n    global latest_speed\n    latest_speed = r.value.magnitude\n    \ndef new_rpm(r):\n    global latest_rpm\n    latest_rpm = r.value.magnitude\n\ndef new_engine_load(r):\n    global latest_engine_load\n    latest_engine_load = r.value.magnitude\n   \ndef new_coolant_temp(r):\n    global latest_coolant_temp\n    latest_coolant_temp = r.value.magnitude\n    \ndef new_intake_pressure(r):\n    global latest_intake_pressure\n    latest_intake_pressure = r.value.magnitude\n    \ndef new_intake_temp(r):\n    global latest_intake_temp\n    latest_intake_temp = r.value.magnitude\n    \ndef new_maf(r):\n    global latest_maf\n    latest_maf = r.value.magnitude\n    \ndef new_distance_w_mil(r):\n    global latest_distance_w_mil\n    latest_distance_w_mil = r.value.magnitude\n    \ndef new_fuel_rail_pressure_direct(r):\n    global latest_fuel_rail_pressure_direct\n    latest_fuel_rail_pressure_direct =  r.value.magnitude\n    \ndef new_commanded_egr(r):\n    global latest_commanded_egr\n    latest_commanded_egr = r.value.magnitude\n    \ndef new_fuel_level(r):\n    global latest_fuel_level\n    latest_fuel_level = r.value.magnitude\n    \ndef new_barometric_pressure(r):\n    global latest_barometric_pressure\n    latest_barometric_pressure = r.value.magnitude\n   \n# callbacks will fire upon receipt of new values\nconnection.watch(obd.commands.SPEED, callback=new_speed)\nconnection.watch(obd.commands.RPM, callback=new_rpm)\nconnection.watch(obd.commands.ENGINE_LOAD, callback=new_engine_load)\nconnection.watch(obd.commands.COOLANT_TEMP, callback=new_coolant_temp)\nconnection.watch(obd.commands.INTAKE_PRESSURE, callback=new_intake_pressure)\nconnection.watch(obd.commands.INTAKE_TEMP, callback=new_intake_temp)\nconnection.watch(obd.commands.MAF, callback=new_maf)\nconnection.watch(obd.commands.DISTANCE_W_MIL, callback=new_distance_w_mil)\nconnection.watch(obd.commands.FUEL_RAIL_PRESSURE_DIRECT, callback=new_fuel_rail_pressure_direct)\nconnection.watch(obd.commands.COMMANDED_EGR, callback=new_commanded_egr)\nconnection.watch(obd.commands.FUEL_LEVEL, callback=new_fuel_level)\nconnection.watch(obd.commands.BAROMETRIC_PRESSURE, callback=new_barometric_pressure)\n\n# start connection\nconnection.start()\n\nwhile True:\n    myLoop()\n    time.sleep(3)\n\ntime.sleep(60000)\nconnection.stop()\n')),(0,i.kt)("h2",{id:"references-6"},"References"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/OBD-II_PIDs"},"Wikipedia"),"\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/VilmaH/Python-OBD-MQTT/blob/master/obdmqtt.py"},"GitHub"),"---"),(0,i.kt)("h2",{id:"sidebar_position-3-2"},"sidebar_position: 3"),(0,i.kt)("h1",{id:"thermocouple"},"Thermocouple"),(0,i.kt)("h3",{id:"hardware-3"},"Hardware"),(0,i.kt)("h3",{id:"script-3"},"Script"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'import time\nimport board\nimport busio\nimport digitalio\nimport adafruit_max31855\nfrom influxdb import InfluxDBClient\n\ndbClient = InfluxDBClient(\'192.168.88.48\', 8086, \'root\', \'root\', \'workshop\')\n\n\nspi = busio.SPI(board.SCK, MOSI=board.MOSI, MISO=board.MISO)\ncs = digitalio.DigitalInOut(board.D5)\n\nmax31855 = adafruit_max31855.MAX31855(spi, cs)\n\nwhile True:\n    try:\n        tempC = max31855.temperature\n        tempF = tempC * 9 / 5 + 32\n        print("Temperature: {} C {} F ".format(tempC, tempF))\n        loginEvents = [{"measurement":"kiln",\n                    "fields": {\n                            "temp": tempC\n                            }\n                  }\n             ]\n        dbClient.write_points(loginEvents)\n        time.sleep(2.0)\n    except:\n        pass\n')),(0,i.kt)("h2",{id:"references-7"},"References"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://www.adafruit.com/product/269"},"Adafruit"),"---"),(0,i.kt)("h2",{id:"sidebar_position-2-4"},"sidebar_position: 2"),(0,i.kt)("h1",{id:"installing-cisco-cloud-wireless-controller-with-kvm"},"Installing Cisco Cloud Wireless Controller with KVM"),(0,i.kt)("h2",{id:"cisco-c9800-cl-with-kvm"},"Cisco c9800-CL with KVM"),(0,i.kt)("h3",{id:"what"},"What?"),(0,i.kt)("p",null,"The Cisco Catalyst c9800-CL is a wireless controller that is part of the Cisco Catalyst 9800 series. It is designed to manage and secure wireless networks, and provides features such as wireless intrusion prevention, location services, and guest access. The c9800-CL model is a cloud-based controller that is designed to be deployed in a virtual environment, and can be used to manage both on-premises and cloud-based wireless networks."),(0,i.kt)("h3",{id:"install-virtualization-sowftware-group"},"Install virtualization sowftware group"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sudo dnf group install --with-optional virtualization\n")),(0,i.kt)("h3",{id:"enable-libvirtd-service"},"Enable libvirtd service"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sudo systemctl start libvirtd && sudo systemctl enable libvirtd\n")),(0,i.kt)("h2",{id:"create-network-bridge-br10"},"Create network bridge br10"),(0,i.kt)("p",null,"???"),(0,i.kt)("h2",{id:"install-virtual-machine"},"Install Virtual Machine"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"virt-install \\\n--connect=qemu:///system \\\n--os-variant=rhel4.0 \\\n--arch=x86_64 \\\n--cpu host \\\n--console pty,target_type=virtio \\\n--hvm \\\n--import \\\n--name=my_c9k_vm \\\n--disk path=C9800-CL.qcow2,bus=ide,format=qcow2,backing_store \\\n--vcpus=1,sockets=1,cores=1,threads=1 \\\n--ram=4096 \\\n--network=network:model=virtio \\\n--network=network:br10,model=virtio \\\n--network=network:model=virtio  \\\n--noreboot \n")),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"We use the backing_store option to virt-install --disk to quickly create a new disk image and avoid writing to the original image we have downloaded. This new disk image can be easily thrown away."),(0,i.kt)("h3",{parentName:"blockquote",id:"to-exit-kvm"},"To exit KVM"),(0,i.kt)("p",{parentName:"blockquote"},"CTRL + ] ")),(0,i.kt)("h3",{id:"if-you-need-to-start-again-use-this-to-destroy-the-vm"},"If you need to start again, use this to destroy the VM"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"virsh destroy fcos\nvirsh undefine --remove-all-storage fcos\n")),(0,i.kt)("h3",{id:"configure-the-controller"},"Configure the controller"),(0,i.kt)("p",null,'The wireless controller is configured with this script. It sets the hostname of the controller to "9800-1" and creates a user with the name "admin" and password "Cisco123", giving the user privilege level 15. The Gigabit Ethernet interfaces 1 and 2 are then configured, with interface 1 being set up with a static IP address and interface 2 being set up as a trunk port with native VLAN 77. VLAN 77 is created and assigned an IP address, and static routes for the 10.10.10.0/24 and 0.0.0.0/0 networks are set up. The 5 GHz and 2.4 GHz radios on the controller are shut down, the country code is set to Great Britain, and the radios are re-enabled. Finally, the virtual wireless LAN controller (VWLC) is configured and the DNS server is set to 1.1.1.1 and the NTP server to pool.ntp.org.'),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-ios"},"conf t\nhostname 9800-1\nuser-name admin\n privilege 15\n password 0 Cisco123\n exit\nint gig 1\n no switchport\n ip address 10.10.10.10 255.255.255.0\n no shut\n exit\nint gig 2\n switchport\n switchport mode trunk\n switchport trunk native vlan 77\n no shut\n exit\nint vlan 77\n ip address 192.168.77.10 255.255.255.0\n no shut\n exit\nip route 10.10.10.0 255.255.255.0 10.10.10.1\nip route 0.0.0.0 0.0.0.0 192.168.77.1\nwireless management interface vlan 77\nap dot11 5ghz shutdown \nap dot11 24ghz shutdown \nap country GB\nno ap dot11 5ghz shutdown\nno ap dot11 24ghz shutdown\nexit\nwireless config vwlc-ssc key-size 2048 signature-algo sha256 password 0 Cisco123\nconf t\nip name-server 1.1.1.1\nntp server pool.ntp.org\n")),(0,i.kt)("h3",{id:"access-the-gui"},"Access the GUI"),(0,i.kt)("p",null,"Now the GUI can be accessed at 192.168.77.1, login and go through the sero day configuration steps to setup a wireless network."),(0,i.kt)("h2",{id:"references-8"},"References"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://docs.fedoraproject.org/en-US/quick-docs/getting-started-with-virtualization/"},"FedoraVirtGuide")),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://www.cisco.com/c/en/us/td/docs/wireless/controller/9800/9800-cloud/installation/b-c9800-cl-install-guide/installing_the_controller_in_kvm_environment.html"},"CiscoGuide")),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://youtu.be/6ttSeDTODWM"},"CiscoSal")),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://youtu.be/MeDwvj0LxhU"},"wireless_boi"),"---"),(0,i.kt)("h2",{id:"sidebar_position-4-2"},"sidebar_position: 4"),(0,i.kt)("h1",{id:"translating-books-with-deepl"},"Translating books with DeepL"),(0,i.kt)("h3",{id:"steps"},"Steps"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"cut off spine of book"),(0,i.kt)("li",{parentName:"ul"},"scan in evey page"),(0,i.kt)("li",{parentName:"ul"},"combine pages into pdf"),(0,i.kt)("li",{parentName:"ul"},"split pdf into small pieces"),(0,i.kt)("li",{parentName:"ul"},"convert pdf pieces into word documents keeping the images in place"),(0,i.kt)("li",{parentName:"ul"},"upload word documents to DeepL translation"),(0,i.kt)("li",{parentName:"ul"},"convert returned translated word documents back into pdf"),(0,i.kt)("li",{parentName:"ul"},"combine all translated pdf pieces back into single translated pdf"),(0,i.kt)("li",{parentName:"ul"},"print")),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-4-3"},"sidebar_position: 4"),(0,i.kt)("h1",{id:"using-openai-api"},"Using OpenAI API"),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-4-4"},"sidebar_position: 4"),(0,i.kt)("h1",{id:"sun-shading-model-with-radiance"},"Sun Shading Model With Radiance"),(0,i.kt)("p",null,"To use Radiance to model sun shading, you will need to follow these steps:"),(0,i.kt)("p",null,"Install Radiance: First, make sure that Radiance is installed on your computer. You can download Radiance from the official website (",(0,i.kt)("a",{parentName:"p",href:"https://radiance-online.org/"},"https://radiance-online.org/"),") or from a package manager such as Homebrew."),(0,i.kt)("p",null,"Create a 3D model of the scene: Use a 3D modeling software such as Rhino or SketchUp to create a 3D model of the building, terrain, and any other objects in the scene. You will need to export the model as a Radiance geometry file (.obj) or a Radiance scene description file (.rad)."),(0,i.kt)("p",null,"Set up the Radiance simulation: Use a text editor to create a Radiance simulation script that specifies the input files, simulation parameters, and output settings. The script should include commands to define the location, time, and sky conditions, as well as the materials, textures, and geometry of the objects in the scene. You can refer to the Radiance documentation for more information on the available commands and options."),(0,i.kt)("p",null,"Run the Radiance simulation: Use the command-line interface to run the Radiance simulation using the script that you created. The simulation will generate a series of output files, including image files that show the shading patterns on the objects in the scene."),(0,i.kt)("p",null,"Analyze the results: Use a software tool such as ImageJ or GIMP to view and analyze the output image files. You can measure the amount of shading at different points on the objects, or you can use color mapping to visualize the shading patterns.---"),(0,i.kt)("h2",{id:"sidebar_position-4-5"},"sidebar_position: 4"),(0,i.kt)("h1",{id:"modeling-a-spherical-solar-concentrator-with-lady-bug"},"Modeling a spherical solar concentrator with Lady Bug"),(0,i.kt)("p",null,"To use Radiance to model sun shading, you will need to follow these steps:"),(0,i.kt)("p",null,"Install Radiance: First, make sure that Radiance is installed on your computer. You can download Radiance from the official website (",(0,i.kt)("a",{parentName:"p",href:"https://radiance-online.org/"},"https://radiance-online.org/"),") or from a package manager such as Homebrew."),(0,i.kt)("p",null,"Create a 3D model of the scene: Use a 3D modeling software such as Rhino or SketchUp to create a 3D model of the building, terrain, and any other objects in the scene. You will need to export the model as a Radiance geometry file (.obj) or a Radiance scene description file (.rad)."),(0,i.kt)("p",null,"Set up the Radiance simulation: Use a text editor to create a Radiance simulation script that specifies the input files, simulation parameters, and output settings. The script should include commands to define the location, time, and sky conditions, as well as the materials, textures, and geometry of the objects in the scene. You can refer to the Radiance documentation for more information on the available commands and options."),(0,i.kt)("p",null,"Run the Radiance simulation: Use the command-line interface to run the Radiance simulation using the script that you created. The simulation will generate a series of output files, including image files that show the shading patterns on the objects in the scene."),(0,i.kt)("p",null,"Analyze the results: Use a software tool such as ImageJ or GIMP to view and analyze the output image files. You can measure the amount of shading at different points on the objects, or you can use color mapping to visualize the shading patterns.---"),(0,i.kt)("h2",{id:"sidebar_position-4-6"},"sidebar_position: 4"),(0,i.kt)("h1",{id:"query-workings"},"Query workings"),(0,i.kt)("p",null,"Identify mines within 2km of given point."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"select * \nfrom osmm_topo.cartographictext \nWHERE ST_DWithin(cartographictext.wkb_geometry,  ST_Transform(ST_GeomFromText(\n              'POINT(  -2.2199 51.69382 )',4326), 27700) , 2000.0)\nAND cartographictext.textstring like '%Workings%';\n")),(0,i.kt)("h2",{id:"references----1"},"References---"),(0,i.kt)("h2",{id:"sidebar_position-7"},"sidebar_position: 7"),(0,i.kt)("h1",{id:"wildlife-corridor-overview"},"Wildlife corridor overview"),(0,i.kt)("h1",{id:"aims"},"Aims"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Identify areas of high connectivity between different land cover types, such as forests and grasslands. These areas are likely to be used by wildlife as corridors for movement.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Identify potential barriers to wildlife movement, such as roads or urban areas"))),(0,i.kt)("h3",{id:"show-column-names"},"Show column names"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT COLUMN_NAME\nFROM INFORMATION_SCHEMA.COLUMNS\nWHERE TABLE_NAME = 'topographicarea'\n")),(0,i.kt)("h3",{id:"show-entries-in-descriptivegroup-column"},"Show entries in descriptivegroup column"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT descriptivegroup\nFROM topographicarea\n")),(0,i.kt)("h3",{id:"show-entries-in-column-which-match-natural-environment-in-descriptivegroup-column"},"Show entries in column which match Natural Environment in descriptivegroup column"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT *\nFROM topographicarea\nWHERE 'Natural Environment' = ANY (descriptivegroup)\n")),(0,i.kt)("h3",{id:"show-entries-in-column-which-match-road-in-descriptivegroup-column"},"Show entries in column which match Road in descriptivegroup column"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT *\nFROM topographicarea\nWHERE 'Road' = ANY (descriptiveterm)\n")),(0,i.kt)("h3",{id:"show-entries-in-column-which-match-building-in-descriptivegroup-column"},"Show entries in column which match Building in descriptivegroup column"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT *\nFROM topographicarea\nWHERE 'Building' = ANY (descriptivegroup)\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(5579).Z,width:"1515",height:"779"})),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(7792).Z,width:"1515",height:"779"})),(0,i.kt)("p",null,"You can see how the edges or roads and railway tracs could be used as wildlife corridors."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(1094).Z,width:"1515",height:"779"})),(0,i.kt)("h2",{id:"references----2"},"References---"),(0,i.kt)("h2",{id:"sidebar_position-3-3"},"sidebar_position: 3"),(0,i.kt)("h1",{id:"land-registry-price-paid-parish"},"Land registry price paid parish"),(0,i.kt)("h2",{id:"download-data"},"Download data"),(0,i.kt)("p",null,"We downloaded a CSV file that contained property price data for the past three years, along with the postal code coordinates and boundary line polygons."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"$ wget bdline_gpkg_gb.zip\n&& unzip bdline_gpkg_gb.zip\n&& cd data\n")),(0,i.kt)("h2",{id:"import-bdline"},"Import bdline"),(0,i.kt)("p",null,"We used ogr2ogr to convert a file containing boundary lines (in a format called GeoPackage) into a PostgreSQL file, changed the projection of the data from OSGB1936 to WGS84, and imported it into a database."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'ogr2ogr \\\n-f "PostgreSQL" \\\n-a_srs "EPSG:27700" \\\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"-t_srs \"EPSG:4326\" \\\n-progress PG:\"dbname='gis' host='$ip' port='5432' user='$user'\npassword='$password'\" \\\nbdline_gb.gpkg\n")),(0,i.kt)("h2",{id:"connect-to-server"},"Connect to server"),(0,i.kt)("p",null,"Starting a psql instance on the client in order to interact with the database on the server."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"psql -h 192.168.88.10 -U postgres gis\n")),(0,i.kt)("h1",{id:"create-priced-paid-polygons-for-every-point"},"Create priced paid polygons for every point"),(0,i.kt)("p",null,"We used point data that was already in the database from a previous project to create a new polygon for each point that was within the boundaries of a parish. We also added the price paid for each house (the point) to the corresponding polygon."),(0,i.kt)("h3",{id:"select"},"SELECT"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"parish.geom,\npoints.pounds\nINTO pp_parish\nFROM\nparish INNER JOIN points\nON st_contains(parish.geom, points.geom);\n")),(0,i.kt)("h2",{id:"find-avarage-point-value-for-duplicate-polygons"},"Find avarage point value for duplicate polygons"),(0,i.kt)("p",null,"Like in the the previous project, we calculated the average value for each of the duplicate polygons."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"SELECT geom,avg(pounds)\nINTO avg_pp_parish\nFROM pp_parish\nGROUP BY geom;\n")),(0,i.kt)("h2",{id:"import-new-price-paid-polygons-to-file"},"Import new price paid polygons to file"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Qgis > Database > DB Manager > Import Layer/File - Name: pp_parish\n")),(0,i.kt)("h2",{id:"add-price-paid-polygons-layer-to-qgis"},"Add price paid polygons layer to Qgis"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Qgis > Layer > Add Layer > Add Vector Layer\nQgis > Database > DB Manager > Import Layer/File - Name: pp_parish\nVector Dataset(s): .shp\n")),(0,i.kt)("h2",{id:"colour-polygons-by-attribute-field"},"Colour polygons by attribute field"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Right click: Layer > Properties\nSymbology > Single Symbol: Gradiated\nVaule: pounds\nColour Ramp: Spectral\nInvert Colour Ramp\nSegmentation: Equal Interval\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(2198).Z,width:"1630",height:"886"}),"---"),(0,i.kt)("h2",{id:"sidebar_position-7-1"},"sidebar_position: 7"),(0,i.kt)("h1",{id:"microclimates"},"Microclimates"),(0,i.kt)("h2",{id:"references-9"},"References"),(0,i.kt)("p",null,"[???]","---"),(0,i.kt)("h2",{id:"sidebar_position-6"},"sidebar_position: 6"),(0,i.kt)("h1",{id:"least-cost-path-wildlife-corridors"},"Least cost path wildlife corridors"),(0,i.kt)("p",null,"Identify the current locations of important wildlife habitats in the study area, such as parks, green spaces, and natural areas.\nIdentify the current barriers to wildlife movement, such as roads, railways, and other infrastructure.\nIdentify potential corridors that could be used by wildlife to move between habitats, such as the edges of railways and roads, the ends of public gardens, and parts of parks.\nEvaluate the feasibility of using each potential corridor for wildlife movement, taking into account factors such as the potential impact on human uses of the area, the potential for conflicts with other land uses, and the potential for habitat degradation or loss.\nUse GIS software to create a map showing the proposed improvements to the urban wildlife corridors, including any modifications that may be needed to make the corridors more usable by wildlife (e.g. the installation of wildlife crossings or fencing).\nConsult with relevant stakeholders, such as local governments, community groups, and environmental organizations, to solicit feedback on the proposed improvements and incorporate any necessary revisions."),(0,i.kt)("h3",{id:"show-column-names-1"},"Show column names"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT COLUMN_NAME\nFROM INFORMATION_SCHEMA.COLUMNS\nWHERE TABLE_NAME = 'topographicarea'\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT *\nFROM topographicarea\nLIMIT 1000\n")),(0,i.kt)("h3",{id:"show-entries-in-descriptivegroup-column-1"},"Show entries in descriptivegroup column"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT descriptivegroup\nFROM topographicarea\n")),(0,i.kt)("h3",{id:"show-entries-in-descriptivegroup-column-2"},"Show entries in descriptivegroup column"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT descriptiveterm\nFROM topographicarea\n")),(0,i.kt)("h3",{id:"select-scrub-land"},"Select scrub land"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT fid, descriptiveterm, wkb_geometry\nFROM topographicarea\nWHERE 'Natural Environment' = ANY (descriptivegroup)\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT fid, descriptiveterm, wkb_geometry\nFROM topographicarea\nWHERE '%Rail%' = LIKE (descriptiveterm)\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(4163).Z,width:"1060",height:"477"})),(0,i.kt)("p",null,"wildlife-corridors-5.png"),(0,i.kt)("h2",{id:"references-10"},"References"),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-3-4"},"sidebar_position: 3"),(0,i.kt)("h1",{id:"flood-risk"},"Flood risk"),(0,i.kt)("p",null,"To calculate flood risk from LiDAR data in PostGIS, you will need to follow these steps:"),(0,i.kt)("p",null,"Import the LiDAR data into PostGIS. This can be done using the ST_LASToSQL function, which will convert the LiDAR data into a format that can be stored in a PostGIS database."),(0,i.kt)("p",null,'Use the ST_Union function to merge all of the LiDAR points into a single geometry. This will create a "point cloud" representation of the terrain.'),(0,i.kt)("p",null,"Use the ST_Triangulate function to triangulate the point cloud. This will create a set of triangular facets, each of which represents a portion of the terrain surface."),(0,i.kt)("p",null,"Use the ST_Dump function to extract the individual triangles from the triangulated surface."),(0,i.kt)("p",null,"Use the ST_Z function to extract the elevation of each vertex of each triangle."),(0,i.kt)("p",null,"Use the ST_Area function to calculate the area of each triangle."),(0,i.kt)("p",null,"Use the ST_Centroid function to calculate the centroid of each triangle."),(0,i.kt)("p",null,"Use the ST_Distance function to calculate the distance from the centroid of each triangle to the nearest river or stream."),(0,i.kt)("p",null,"Use the elevation and distance information to calculate the flood risk for each triangle."),(0,i.kt)("p",null,"Use the ST_Union function to merge all of the triangles into a single polygon, and use the ST_ConvexHull function to create a convex hull around the polygon."),(0,i.kt)("p",null,"Use the ST_Intersection function to calculate the intersection between the convex hull and the floodplain."),(0,i.kt)("p",null,"Use the ST_Area function to calculate the area of the intersection, and use this value to calculate the overall flood risk for the region."),(0,i.kt)("h2",{id:"references----3"},"References---"),(0,i.kt)("h2",{id:"sidebar_position-3-5"},"sidebar_position: 3"),(0,i.kt)("h1",{id:"land-registry-price-paid-parcels"},"Land registry price paid parcels"),(0,i.kt)("p",null,'We combined three separate files containing price paid data into a single file, removed unnecessary quotes, selected only rows that contained the string "GL" followed by a number between 0 and 9, and printed out only the fourth and second columns. We also added column names and deleted any rows that contained null values.'),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'$ cat pp-2018.csv pp-2019.csv pp-2020.csv | tr -d \'"\' > pp_3year.csv \\\n&& awk -F"," \'/GL+[0-9]/ { print $4 "," $2}\' pp_3year.csv > gl_p_3.csv \\\n&& { echo "postcode, pounds"; cat gl_p_3.csv; } > prices.csv \\\n&& sed -i \'/\\\\N/d\' prices.csv\n')),(0,i.kt)("h2",{id:"prepare-location-data"},"Prepare location data"),(0,i.kt)("p",null,"We used the same process to clean and filter the data as we did for the price data, except we did not need to concatenate multiple files together."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'$ awk -F"," \'/GL+[0-9]/ { print $1 "," $8 "," $9}\' open_postcode_geo.csv >\ngl_l.csv \\\n&& { echo "postcode, latitude, longitude"; cat gl_l.csv; } >\ncoordinates.csv \\\n&& sed -i \'/\\\\N/d\' coordinates.csv\n')),(0,i.kt)("h2",{id:"import-parcels"},"Import parcels"),(0,i.kt)("p",null,"We used ogr2ogr to convert a file containing cadastral parcel information (in GML format) into a PostgreSQL file, changed the projection of the data from OSGB to WGS84, and imported it into a database."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"ogr2ogr \\\n-f \"PostgreSQL\" \\\n-a_srs \"EPSG:27700\" \\\n-t_srs \"EPSG:27700\" \\\n-nln parcels \\\n-progress \\\nPG:\"dbname='postgres' host='0.0.0.0' port='5432' user='postgres'\npassword='postgres'\" \\\nLand_Registry_Cadastral_Parcels.gml\n")),(0,i.kt)("h2",{id:"connect-to-server-1"},"Connect to server"),(0,i.kt)("h2",{id:"set-psql-password"},"set psql password"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"export PGPASSWORD=postgres\n")),(0,i.kt)("p",null,"We started a psql session on the client computer to allow us to communicate with the database that is stored on the server."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"psql -h 0.0.0.0 -U postgres\n")),(0,i.kt)("h2",{id:"create-prices-table"},"Create prices table"),(0,i.kt)("p",null,"We created a new empty table with a primary key column of type serial (which will automatically increment) and two additional columns: one for text data (postcodes) and one for integer data (pounds)."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"CREATE TABLE prices (\np_prices_id serial PRIMARY KEY,\np_postcode TEXT NOT NULL,\npounds INTEGER NOT NULL\n);\n")),(0,i.kt)("h2",{id:"create-location-table"},"Create location table"),(0,i.kt)("p",null,"We created a similar empty table for storing location data, but with columns for latitude and longitude rather than a column for pounds."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"CREATE TABLE coordinates (\nc_id serial PRIMARY KEY,\nc_postcode TEXT NOT NULL,\nlatitude FLOAT NOT NULL,\nlongitude FLOAT NOT NULL\n);\n")),(0,i.kt)("h2",{id:"populate-prices-table"},"Populate prices table"),(0,i.kt)("p",null,"We used the \\copy command in psql to import the price data into the new price column in the database."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"\\copy prices(p_postcode, pounds) FROM '/home/reuben/Downloads/prices.csv'\nDELIMITER ',' CSV HEADER;\n")),(0,i.kt)("h2",{id:"populate-coordinates-table"},"Populate coordinates table"),(0,i.kt)("p",null,"We repeat the process for the coordinates data."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"\\copy coordinates(c_postcode, latitude, longitude) FROM\n'/home/reuben/Downloads/coordinates.csv' DELIMITER ',' CSV HEADER;\n")),(0,i.kt)("h1",{id:"join-coordinates-and-prices-into-points"},"Join coordinates and prices into points"),(0,i.kt)("p",null,"We used the JOIN command in SQL to create a new table that combines the prices and coordinates data based on their shared postcodes."),(0,i.kt)("h3",{id:"select-1"},"SELECT"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"c_id,\nc_postcode,\nlatitude,\nlongitude,\npounds\nINTO points\nFROM coordinates INNER JOIN prices\nON coordinates.c_postcode = prices.p_postcode;\n")),(0,i.kt)("h1",{id:"add-geometry-column-to-points"},"Add geometry column to points"),(0,i.kt)("p",null,"We added a new column to the table to store geometry data."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"ALTER TABLE points ADD COLUMN geom GEOMETRY(Point, 4326 );\n")),(0,i.kt)("h1",{id:"update-points-from-coordinates"},"Update points from coordinates"),(0,i.kt)("p",null,"We used the data in the latitude and longitude columns to create points and stored them in the geometry column."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"UPDATE points SET geom = ST_SETSRID(ST_MakePoint(longitude,\nlatitude), 4326 );\n")),(0,i.kt)("h1",{id:"create-priced-polygons"},"Create priced polygons"),(0,i.kt)("p",null,"For each point within a polygon, we created a new polygon and added the corresponding price paid for the point to it."),(0,i.kt)("h3",{id:"select-2"},"SELECT"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"c_id,\nparcels.wkb_geometry,\npoints.pounds\nINTO polygons\nFROM\nparcels INNER JOIN points\nON st_contains(parcels.wkb_geometry, points.geom);\n")),(0,i.kt)("h2",{id:"find-avarage-point-value-for-duplicate-polygons-1"},"Find avarage point value for duplicate polygons"),(0,i.kt)("p",null,"We calculated the average value for each of the duplicate polygons."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"SELECT c_id,geom,avg(pounds)\nINTO avg_polygons\nFROM polygons\nGROUP BY geom;\n")),(0,i.kt)("h2",{id:"import-new-price-paid-polygons-to-file-1"},"Import new price paid polygons to file"),(0,i.kt)("p",null,"We used QGIS to export the table from the database."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Qgis > Database > DB Manager > Import Layer/File - Name: avg_polygons\n")),(0,i.kt)("h2",{id:"add-price-paid-polygons-layer-to-qgis-1"},"Add price paid polygons layer to Qgis"),(0,i.kt)("p",null,"Displaying the layer in Qgis."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Qgis > Layer > Add Layer > Add Vector Layer\nQgis > Database > DB Manager > Import Layer/File - Name: avg_polygons\nVector Dataset(s): .shp\n")),(0,i.kt)("h2",{id:"colour-polygons-by-attribute-field-1"},"Colour polygons by attribute field"),(0,i.kt)("p",null,"We modified the layer properties in order to create a visually appealing effect."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Right click: Layer > Properties\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Symbology > Single Symbol: Graduated\nValue: pounds\nColour Ramp: Spectral\nInvert Colour Ramp\nSegmentation: Equal Interval\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docusaurus Plushie",src:a(9903).Z,width:"1534",height:"787"})),(0,i.kt)("h2",{id:"download-data-1"},"Download data"),(0,i.kt)("p",null,"We downloaded a CSV file that contained property price data for the past three years, along with the postal code coordinates and boundary line polygons."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"$ wget bdline_gpkg_gb.zip\n&& unzip bdline_gpkg_gb.zip\n&& cd data\n")),(0,i.kt)("h2",{id:"import-bdline-1"},"Import bdline"),(0,i.kt)("p",null,"We used ogr2ogr to convert a file containing boundary lines (in a format called GeoPackage) into a PostgreSQL file, changed the projection of the data from OSGB1936 to WGS84, and imported it into a database."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'ogr2ogr \\\n-f "PostgreSQL" \\\n-a_srs "EPSG:27700" \\\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"-t_srs \"EPSG:4326\" \\\n-progress PG:\"dbname='gis' host='$ip' port='5432' user='$user'\npassword='$password'\" \\\nbdline_gb.gpkg\n")),(0,i.kt)("h2",{id:"connect-to-server-2"},"Connect to server"),(0,i.kt)("p",null,"Starting a psql instance on the client in order to interact with the database on the server."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"psql -h 192.168.88.10 -U postgres gis\n")),(0,i.kt)("h1",{id:"create-priced-paid-polygons-for-every-point-1"},"Create priced paid polygons for every point"),(0,i.kt)("p",null,"We used point data that was already in the database from a previous project to create a new polygon for each point that was within the boundaries of a parish. We also added the price paid for each house (the point) to the corresponding polygon."),(0,i.kt)("h3",{id:"select-3"},"SELECT"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"parish.geom,\npoints.pounds\nINTO pp_parish\nFROM\nparish INNER JOIN points\nON st_contains(parish.geom, points.geom);\n")),(0,i.kt)("h2",{id:"find-avarage-point-value-for-duplicate-polygons-2"},"Find avarage point value for duplicate polygons"),(0,i.kt)("p",null,"Like in the the previous project, we calculated the average value for each of the duplicate polygons."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"SELECT geom,avg(pounds)\nINTO avg_pp_parish\nFROM pp_parish\nGROUP BY geom;\n")),(0,i.kt)("h2",{id:"import-new-price-paid-polygons-to-file-2"},"Import new price paid polygons to file"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Qgis > Database > DB Manager > Import Layer/File - Name: pp_parish\n")),(0,i.kt)("h2",{id:"add-price-paid-polygons-layer-to-qgis-2"},"Add price paid polygons layer to Qgis"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Qgis > Layer > Add Layer > Add Vector Layer\nQgis > Database > DB Manager > Import Layer/File - Name: pp_parish\nVector Dataset(s): .shp\n")),(0,i.kt)("h2",{id:"colour-polygons-by-attribute-field-2"},"Colour polygons by attribute field"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Right click: Layer > Properties\nSymbology > Single Symbol: Gradiated\nVaule: pounds\nColour Ramp: Spectral\nInvert Colour Ramp\nSegmentation: Equal Interval\n```---\nsidebar_position: 1\n---\n\n# Setting up PostGIS Database Server\n\n### Create a pod\n``` bash\npodman pod create -p 8080:8080 -p 5432:5432 -n geospatial\n")),(0,i.kt)("h3",{id:"run-image-in-pod-2"},"Run image in pod"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman run \\\n--pod geospatial \\\n--name postgis \\\n-e POSTGRES_PASSWORD=postgres \\\n-d postgis/postgis\n")),(0,i.kt)("h3",{id:"auto-gen-systemd-file"},"auto gen systemd file"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman generate systemd postgis >\n/home/$user/.config/systemd/user/postgis.service\n")),(0,i.kt)("h3",{id:"start-postgis-service"},"start postgis service"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl start --user postgis.service\n")),(0,i.kt)("h3",{id:"enable-postgis-service"},"enable postgis service"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl start --user postgis.service\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman start postgis\n")),(0,i.kt)("h2",{id:"check"},"Check"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"psql -h localhost -p 5432 -U postgres \n")),(0,i.kt)("h3",{id:"generate-yaml-file-1"},"Generate YAML file"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman generate kube geospatial -f geospatial-stack-podman.yaml\n")),(0,i.kt)("h2",{id:"heres-the-yaml-file-1"},"Here's the YAML file"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},'\n# Save the output of this file and use kubectl create -f to import\n# it into Kubernetes.\n#\n# Created with podman-4.3.1\napiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    io.kubernetes.cri-o.ContainerType/geoserver: container\n    io.kubernetes.cri-o.ContainerType/postgis: container\n    io.kubernetes.cri-o.SandboxID/geoserver: 5579c50f78551192cbc7eafed6f04db71155c3690d677c9a5741b25fe54fc14\n    io.kubernetes.cri-o.SandboxID/postgis: 5579c50f78551192cbc7eafed6f04db71155c3690d677c9a5741b25fe54fc14\n    io.kubernetes.cri-o.TTY/geoserver: "true"\n    io.kubernetes.cri-o.TTY/postgis: "true"\n    io.podman.annotations.autoremove/geoserver: "FALSE"\n    io.podman.annotations.autoremove/postgis: "FALSE"\n    io.podman.annotations.init/geoserver: "FALSE"\n    io.podman.annotations.init/postgis: "FALSE"\n    io.podman.annotations.privileged/geoserver: "FALSE"\n    io.podman.annotations.privileged/postgis: "FALSE"\n    io.podman.annotations.publish-all/geoserver: "FALSE"\n    io.podman.annotations.publish-all/postgis: "FALSE"\n  creationTimestamp: "2022-12-30T13:47:48Z"\n  labels:\n    app: geospatial\n  name: geospatial\nspec:\n  automountServiceAccountToken: false\n  containers:\n  - env:\n    - name: GEOSERVER_ADMIN_USER\n      value: postgres\n    - name: GEOSERVER_ADMIN_PASSWORD\n      value: postgres\n    image: docker.io/kartoza/geoserver:latest\n    name: geoserver\n    ports:\n    - containerPort: 5432\n      hostPort: 5432\n    - containerPort: 8080\n      hostPort: 8080\n    resources: {}\n    securityContext:\n      capabilities:\n        drop:\n        - CAP_MKNOD\n        - CAP_NET_RAW\n        - CAP_AUDIT_WRITE\n    tty: true\n  - env:\n    - name: POSTGRES_PASS\n      value: postgres\n    - name: POSTGRES_USER\n      value: postgres\n    image: docker.io/kartoza/postgis:latest\n    name: postgis\n    resources: {}\n    securityContext:\n      capabilities:\n        drop:\n        - CAP_MKNOD\n        - CAP_NET_RAW\n        - CAP_AUDIT_WRITE\n    tty: true\n    volumeMounts:\n    - mountPath: /var/lib/postgresql\n      name: 3276e85c3fc649e1904e0161ff79599dcc3292e9121982d648c0f2c47585abaf-pvc\n  enableServiceLinks: false\n  hostname: geospatial\n  restartPolicy: Never\n  volumes:\n  - name: 3276e85c3fc649e1904e0161ff79599dcc3292e9121982d648c0f2c47585abaf-pvc\n    persistentVolumeClaim:\n      claimName: 3276e85c3fc649e1904e0161ff79599dcc3292e9121982d648c0f2c47585abaf\nstatus: {}\n')),(0,i.kt)("h3",{id:"test-yaml-file-1"},"Test YAML file"),(0,i.kt)("h4",{id:"remove-postgis-container"},"Remove postgis container"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman rm -vf postgis\n")),(0,i.kt)("h4",{id:"remove-geoserver-container"},"Remove geoserver container"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman rm -vf geoserver\n")),(0,i.kt)("h4",{id:"remove-spatial-pod"},"Remove spatial pod"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman pod rm spatial\n")),(0,i.kt)("h4",{id:"install-everything-again-using-the-yaml-file"},"Install everything again using the YAML file"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"podman play kube geospatial-stack-podman.yaml\n```---\nsidebar_position: 2\n---\n\n# Network Status Map\n\n## To do\n- cross platform smart phone app that can scan qr code and post to database along with gps location\n- can select whether being deployed or derigged after scanned\n- show map of network status of devices on map\n- database connects to cloud controller / router for network status\n\n\n\n\n## References\n---\nsidebar_position: 2\n---\n\n# Toggle map\n\n``` php\n<?php\n\n// Connect to the database\n$db = new PDO('pgsql:host=your_host;dbname=your_database', 'your_username', 'your_password');\n\n// Get the geometry data from the database\n$stmt = $db->prepare('SELECT * FROM your_table WHERE your_column = :value');\n$stmt->execute(array(':value' => $_GET['value']));\n$geometry = $stmt->fetchAll(PDO::FETCH_ASSOC);\n\n// Return the geometry data as JSON\nheader('Content-Type: application/json');\necho json_encode($geometry);\n\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-javascript"},'\x3c!-- Add the Leaflet CSS and JavaScript files to the page --\x3e\n<link rel="stylesheet" href="https://unpkg.com/leaflet@1.7.1/dist/leaflet.css" />\n<script src="https://unpkg.com/leaflet@1.7.1/dist/leaflet.js"><\/script>\n\n\x3c!-- Create a div element for the map --\x3e\n<div id="map"></div>\n\n\x3c!-- Add buttons to the page --\x3e\n<button id="button1">Button 1</button>\n<button id="button2">Button 2</button>\n\n\x3c!-- Initialize the map and add a tile layer --\x3e\n<script>\n  // Create the map and set the view to a default location\n  var map = L.map(\'map\').setView([51.505, -0.09], 13);\n\n  // Add a tile layer to the map\n  L.tileLayer(\'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\', {\n    attribution: \'Map data &copy; <a href="https://www.openstreetmap.org/">OpenStreetMap\n```---\nsidebar_position: 2\n---\n\n# Loading Land registry inspire polygons\n\n### Download data\n\nDownloading a csv file of property price paid data for each of the last three years, postcode coordinates, and land registry cadastral parcels for Stoud.\n\n``` bash\nwget https://use-land-property-\ndata.service.gov.uk/datasets/inspire/download/Stroud.zip \\\n&& unzip Stroud.zip\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"psql -h localhost -p 5432 -U postgres \n")),(0,i.kt)("h3",{id:"create-table"},"create table"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE inspire-polygons-stroud (\n  geom geometry(Geometry,4326),\n  properties jsonb\n);\n")),(0,i.kt)("h3",{id:"import-parcels-1"},"Import parcels"),(0,i.kt)("p",null,"Using ogr2ogr "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'ogr2ogr -f "PostgreSQL" "PG:host=0.0.0.0 user=postgres dbname=public password=postgres" *.shp -nln inspire-polygons-stroud\n')),(0,i.kt)("h2",{id:"create-spatial-index"},"Create spatial index"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE INDEX inspire-polygons-stroud-gist ON inspire-polygons-stroud USING GIST (geom);\n")),(0,i.kt)("h2",{id:"references-11"},"References"),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-4-7"},"sidebar_position: 4"),(0,i.kt)("h1",{id:"loading-ordnance-survey-mastermap-with-astun-loader"},"Loading Ordnance Survey MasterMap with astun loader"),(0,i.kt)("h2",{id:"to-do-2"},"To do"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Setup loader in pod?")),(0,i.kt)("h3",{id:"install-astun-loader"},"Install astun loader"),(0,i.kt)("p",null,"Download loader"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/AstunTechnology/Loader.git\n\n")),(0,i.kt)("h3",{id:"change-directory"},"Change directory"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"cd Loader\n")),(0,i.kt)("p",null,"Install dependancies "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sudo dnf install gdal\n")),(0,i.kt)("p",null,"make directories"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir source temporary output\n")),(0,i.kt)("h3",{id:"prepare-data"},"Prepare data"),(0,i.kt)("p",null,"Download MasterMap data"),(0,i.kt)("p",null,"wget ???"),(0,i.kt)("p",null,"Unzip mastermap data to source directory"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"unzip OS_order_6148593_OSMasterMapTopography5km_2022-12-22_1.zip -d source\n")),(0,i.kt)("p",null,"Remove manifest text file in source directory"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"rm source/manifest.txt\n")),(0,i.kt)("h3",{id:"edit-loader-configuration"},"Edit loader configuration"),(0,i.kt)("p",null,"Backup original"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"cp python/loader.config python/loader.config.bak\n")),(0,i.kt)("p",null,"Replace line 8 source directory"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sed -i '8s/.*/src_dir=\\$HOME\\/Loader\\/source/' python/loader.config\n")),(0,i.kt)("p",null,"Replace line 13 temp directory"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sed -i '13s/.*/tmp_dir=\\$HOME\\/Loader\\/temporary/' python/loader.config\n")),(0,i.kt)("p",null,"Replace line 17 output directory"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sed -i '17s/.*/out_dir=\\$HOME\\/Loader\\/output/' python/loader.config\n")),(0,i.kt)("p",null,"Change line 29 database parameters"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sed -i '29s/.*/ogr_cmd=ogr2ogr --config GML_EXPOSE_FID NO -append -skipfailures -f PostgreSQL PG:\\x27dbname=postgres active_schema=public host=0\\.0\\.0\\.0 user=postgres password=postgres\\x27 \\$file_path/' python/loader.config\n")),(0,i.kt)("h3",{id:"run-ashtun-loader"},"Run ashtun loader"),(0,i.kt)("p",null,"Change directory"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"cd python\n")),(0,i.kt)("p",null,"Run"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"python loader.py loader.config\n")),(0,i.kt)("h3",{id:"qgis-style"},"Qgis style"),(0,i.kt)("p",null,"Launch qgis"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"super, then type qgis, then enter")),(0,i.kt)("p",null,"Create new project"),(0,i.kt)("p",null,"Set default CRS to OSGB"),(0,i.kt)("p",null,"Connect to PostGIS"),(0,i.kt)("p",null,"connect to postgres"),(0,i.kt)("p",null,"Add each layer to project"),(0,i.kt)("p",null,"Download styles"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/OrdnanceSurvey/OS-Master-Map-Topography.git\n")),(0,i.kt)("p",null,"Attach corrosponding styles to each layer"),(0,i.kt)("p",null,"Copy symbols"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"cp -R osmmsymbol $directory $svgdirectory\n")),(0,i.kt)("p",null,"Copy font"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"cp font to font directory\n")),(0,i.kt)("p",null,"Make Qgis plugins work"),(0,i.kt)("h2",{id:"references-12"},"References"),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-5-1"},"sidebar_position: 5"),(0,i.kt)("h1",{id:"ordnance-survey-satellite-imagery-with-raster2pgsql"},"Ordnance survey satellite imagery with raster2pgsql"),(0,i.kt)("h3",{id:"load-sattelite-data-with-either-raster2pgsql-or-ogr2ogr"},"Load sattelite data with either raster2pgsql or ogr2ogr"),(0,i.kt)("h3",{id:"connect-to-database"},"Connect to database"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"psql -h 0.0.0.0 -p 5432 -U postgres  -d postgres\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE EXTENSION postgis_raster;\n")),(0,i.kt)("h3",{id:"load-sattelite-data-with-either-raster2pgsql-or-ogr2ogr-1"},"Load sattelite data with either raster2pgsql or ogr2ogr"),(0,i.kt)("h3",{id:"unzip-all-zips"},"unzip all zips"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'find . -name "*.zip" -exec unzip {} \\;\n')),(0,i.kt)("h2",{id:"set-psql-password-1"},"set psql password"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"export PGPASSWORD=postgres\n")),(0,i.kt)("h3",{id:"raster2pgsql"},"raster2pgsql"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"raster2pgsql -s 27700 -I -C -M -F  *.JPG public.bristol_osmm_satellite_imagery | psql -h 0.0.0.0 -p 5432 -U postgres \n")),(0,i.kt)("h3",{id:"add-a-spatial-index"},"Add a spatial index"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE INDEX bristol_osmm_satellite_imagery__gist ON bristol_osmm_satellite_imagery_ USING GIST (ST_ConvexHull(rast));\n")),(0,i.kt)("h2",{id:"references-13"},"References"),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-3-6"},"sidebar_position: 3"),(0,i.kt)("h1",{id:"ordnance-survey-lidar-data-with-raster2pgsql"},"Ordnance survey lidar data with raster2pgsql"),(0,i.kt)("h3",{id:"load-lidar-data-with-either-raster2pgsql"},"Load lidar data with either raster2pgsql"),(0,i.kt)("h3",{id:"connect-to-database-1"},"Connect to database"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"psql -h 0.0.0.0 -p 5432 -U postgres  -d postgres\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE EXTENSION postgis_raster;\n")),(0,i.kt)("h3",{id:"load-sattelite-data-with-either-raster2pgsql-or-ogr2ogr-2"},"Load sattelite data with either raster2pgsql or ogr2ogr"),(0,i.kt)("h3",{id:"unzip-all-zips-1"},"unzip all zips"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'find . -name "*.zip" -exec unzip {} \\;\n')),(0,i.kt)("h2",{id:"set-psql-password-2"},"set psql password"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"export PGPASSWORD=postgres\n")),(0,i.kt)("h3",{id:"raster2pgsql-1"},"raster2pgsql"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"raster2pgsql -s 27700 -I -C -M -F  *.tif public.bristol_lidar_dtm_1m | psql -h 0.0.0.0 -p 5432 -U postgres --password postgres\n")),(0,i.kt)("h3",{id:"add-a-spatial-index-1"},"Add a spatial index"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE INDEX bristol_lidar_dtm_gist ON bristol_lidar_dtm_1m USING GIST (ST_ConvexHull(rast));\n")),(0,i.kt)("h2",{id:"references-14"},"References"),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-1-5"},"sidebar_position: 1"),(0,i.kt)("h1",{id:"loading-bristol-city-council-geojson-files"},"Loading Bristol city council GeoJson files"),(0,i.kt)("h3",{id:"loop-over-geojson-files-and-create-a-new-table-for-each-and-upload"},"Loop over geojson files and create a new table for each and upload"),(0,i.kt)("p",null,"This script will create a new table in the PostgreSQL database for each .geojson file in the specified directory, using the file name (without the .geojson extension) as the table name. The GeoJSON data from each file will be imported into the corresponding table."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'#!/bin/bash\n\n# Set the database connection string\nconn_string="host=0.0.0.0 user=postgres dbname=postgres password=postgres"\n\n# Loop over all .geojson files in the directory\nfor file in *.geojson; do\n    # Extract the file name without the .geojson extension\n    tablename=$(basename "$file" .geojson)\n    # Use ogr2ogr to import the file into a new table\n    ogr2ogr -f "PostgreSQL" -s_srs EPSG:4326 -t_srs EPSG:27700 PG:"$conn_string" "$file" -nln "$tablename"\ndone\n')),(0,i.kt)("h3",{id:"add-a-spatial-index-2"},"Add a spatial index"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE INDEX bristol-council ON bristol-council USING GIST (geom);\n")),(0,i.kt)("h2",{id:"references-15"},"References"),(0,i.kt)("hr",null),(0,i.kt)("h2",{id:"sidebar_position-1-6"},"sidebar_position: 1"),(0,i.kt)("h1",{id:"identify-flat-terrain-with-above-average-sun"},"Identify flat terrain with above average sun"),(0,i.kt)("p",null,"To identify flat areas in lidar data using GDAL and GRASS in Python, you can use the following steps:"),(0,i.kt)("h3",{id:"import-the-necessary-modules"},"Import the necessary modules"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from osgeo import gdal\nimport grass.script as gs\n")),(0,i.kt)("h3",{id:"set-the-grass-gis-environment"},"Set the GRASS GIS environment"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"gisbase = '/usr/local/grass78'\ngs.set_gisbase(gisbase)\nlocation = 'location'\nmapset = 'mapset'\ngs.run_command('g.proj', georef='path/to/georeferenced_file.tif', location=location)\n")),(0,i.kt)("h3",{id:"import-the-lidar-data-into-grass-gis"},"Import the lidar data into GRASS GIS"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"gs.run_command('r.in.lidar', input='path/to/lidar_data.las', output='lidar_data', flags='e')\n")),(0,i.kt)("p",null,"Calculate the slope of the lidar data using the r.slope.aspect module:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"gs.run_command('r.slope.aspect', elevation='lidar_data', slope='slope', aspect='aspect')\n")),(0,i.kt)("h3",{id:"identify-flat-areas-by-selecting-pixels-with-a-slope-less-than-a-certain-threshold"},"Identify flat areas by selecting pixels with a slope less than a certain threshold"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'gs.mapcalc("flat = if(slope < 0.1, 1, null())")\n')),(0,i.kt)("p",null,"If you want to also consider sunlight exposure, you can use the r.sun module to calculate solar radiation and sky view factor. For example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"gs.run_command('r.sun', elevation='lidar_data', solar_radiation='solar_radiation', sky_view_factor='sky_view_factor')\n")),(0,i.kt)("p",null,"You can then use map algebra to select pixels that have both low slope and high solar radiation or sky view factor. For example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'gs.mapcalc("flat_sunny = if(slope < 0.1 && solar_radiation > 500, 1, null())")\n')))}p.isMDXComponent=!0},8640:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-1-43f5d793112b5e7d965dd45b486ad82e.png"},1726:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-10-dfcbbad19705932c13a95718ea657cb5.png"},8855:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-11-60332f3067091585939f287871665169.png"},9947:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-12-767c10f258be4ccea3fd505a9fe69224.png"},145:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-2-8cbb5ba2a17084da185d97d130f94089.png"},450:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-3-02b772b8c9905ff1d1ad5f175ada8c7f.png"},2040:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-4-ec53deac98415e65bcd3d9a83ce662de.png"},7616:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-5-0837bbfde76f3cace5346b723ccf3f01.png"},74:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-6-8391a5b4741d6b85cb51feabd31d5d9e.png"},5147:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-7-5dba3500b25db255c1561d822aaddb58.png"},4945:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-8-0df5a16690d814e3846e2204c1160f06.png"},5829:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bha-9-337f5cad895cc88b4703da28a5e97070.png"},7451:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/clamp-2-e4b9c5f251ca653bb54536f8fbeac9e2.jpg"},7332:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/clamp-3-bf41914d25c1ad3f8d67fd43bece0453.jpg"},8185:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/egg-1-2edd5330f8680fdf901b10dfe36b1e4f.jpg"},1434:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/egg-2-128d75277af2454dd729a83dce079a5f.jpg"},9766:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-1-cc394510540878b1db9af7ab6425ba6e.png"},6124:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-10-e590620e90d54583a7c925531532800d.png"},6226:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-11-db344785e93b4deba7df1e0f718c7f49.png"},7833:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-12-762be4fc426d16b0a53ac39c4e3706ad.png"},6797:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-13-41841905f5ef1966ec490fc294b126cb.png"},1402:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-2-e218452403e2c570171152bf190e0599.png"},5660:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-3-be893cced12c382bc31c3ba89c78b3fa.png"},3692:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-4-330cfcd0ea4c359ce6e5ca5545ee838c.png"},7392:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-5-bc1bfb367162c27a42899ba9716cea06.png"},3739:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-6-b8361ce67354367b03ad30192b8fde85.png"},4963:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-7-da5a9a3acdd123db154cf1230f08c440.png"},8849:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-8-a4ea6ddf934f19297940891d4477aec4.png"},9718:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ergo-9-67186039105d35dfdb999b333583fff3.png"},5040:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ms-3-2590f4b40b77944ad4a5b2da77317e9b.png"},9903:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/price-paid-parcel-b58fdcacf1b5265bca273e23e59ebb2e.jpg"},2198:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/price-paid-parish-7dab74e8696d5ee03d431495e4fbf360.jpg"},8304:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/pudding-brook-d25c192f63cca338f2a181d2f09cd3e2.jpg"},5158:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/solar-concentrator-1-ad93c8af9d3ae3260d0f3868784455c9.jpg"},2078:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/solar-concentrator-3-e219fb0426d36846e8be8dc7d33746c2.jpg"},8921:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/solar-concentrator-4-5274580557a604c66ded0bb0545bc923.jpg"},380:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/stage-1-82e129b0df05a3dc89abe4fe84e5cd34.jpg"},6219:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/stage-10-ca0b1f0d0eec65bb8455d9793ed7390e.jpg"},3013:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/stage-2-96efdfde9bce24cd310ea2c85c3adbb5.jpg"},9076:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/stage-3-f13d41dad830cad645c00222c4afabd5.jpg"},5800:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/stage-4-367f329abb10ff4d1f0e1eede7a9c0d6.jpg"},2323:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/stage-6-2cb158e56730a299f2ecd3b9b490e4ac.jpg"},3542:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/stage-7-536a8dc3915c3bc552fc3a732e057602.jpg"},7139:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/stage-8-27308a0483995332cca67e02fbdec9fc.jpg"},8997:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/truss-1-262854f9f04c2addb3451e2e0e292058.jpg"},2842:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/truss-2-246d90b00e94dc787904ed511746731a.jpg"},9173:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/truss-3-c6a73cf924e89c582875520935c6855e.png"},5579:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/wildlife-corridors-1-1ce329c2a2f8d1989749a1ef7d4b777c.png"},7792:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/wildlife-corridors-2-eb49b628a2413b5bc0ee68d7928e2cb7.png"},1094:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/wildlife-corridors-3-c269ec2c78bdda23a3a61fd8e8005f4b.png"},4163:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/wildlife-corridors-4-2b389bcac931726d6796b4a4b7a514c0.png"},5670:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/windsor-2-39e8180d320a26f71bcee791cac177ca.png"}}]);